# Project Weaver Plan: [PROJECT_NAME] - Autonomic Development Blueprint  weaver_plan_v1.0 (ULTRA_GRANULAR_EDITION)

**Project ID (ğŸ•¸ï¸N_project_id):** `[AUTO_GENERATED_OR_USER_DEFINED_UNIQUE_ID]`
**Project Weaver Version Context:** `UMI v9.0 - Autonomic Tapestry Edition`
**Date Created:** `YYYY-MM-DD`
**Last Updated:** `YYYY-MM-DD`
**Overall Goal:** `[Clear, concise statement of what this project aims to achieve. E.g., "Develop a scalable, secure, multi-tenant SaaS platform for real-time collaborative document editing with AI-powered suggestions and version control."]`

---

## ğŸ¯ Section 1: Project Initialization & Ecosystem Setup (Phase: `SYS_INIT_ECO_001`)

**Pheromone Focus (Initial trailğŸ“ˆ for this Phase):** `ecosystem_bootstrap_critical_path`
**Objective:** Establish, verify, and document all foundational infrastructure, services, security baselines, core ğŸ•¸ï¸Cognitive Canvas entries, and initial project governance required for sustained autonomous development.

### 1.1. Define Core Project Charter in ğŸ•¸ï¸Cognitive Canvas (Î¼T_SYS_INIT_CHARTER_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` -> `ğŸ§ cognitive_navigator`
    *   **Task Description:** Create/Update the primary `Project_ğŸ•¸ï¸N` in the ğŸ•¸ï¸Cognitive Canvas with comprehensive charter metadata.
    *   **Input Data:**
        *   `project_name`: "[PROJECT_NAME]"
        *   `project_vision`: "[Longer-term vision for the project beyond initial goal]"
        *   `project_goal_primary`: "[Overall Goal Statement from above]"
        *   `project_scope_inclusions`: "[Bulleted list of key things IN scope]"
        *   `project_scope_exclusions`: "[Bulleted list of key things OUT of scope]"
        *   `stakeholders_primary_ğŸ•¸ï¸N_ids`: `["USER_STAKEHOLDER_GROUP_01", "BUSINESS_OWNER_01"]` (Conceptual, link to stakeholder ğŸ•¸ï¸Ns if they exist)
        *   `initial_op_profile_preference`: "[e.g., MAX_QUALITY_SETUP, BALANCED_INIT]"
        *   `initial_tech_profile_preference`: "[e.g., PYTHON_FASTAPI_POSTGRES_REACT_DOCKER_AWS, JAVA_SPRING_MYSQL_ANGULAR_K8S_AZURE]"
        *   `estimated_complexity_ğŸ²R_initial`: `[Low/Medium/High/VeryHigh]`
        *   `target_milestone_1_date_estimate`: `[YYYY-MM-DD]`
        *   `budget_code_ğŸ¦_initial_allocation`: `[Currency Amount or Computational Units]`
    *   **Action (Conceptual, by `ğŸ§ cognitive_navigator`):** Cypher to create/update `Project_ğŸ•¸ï¸N` and link to preferred `ğŸ•¸ï¸N_op_profile` and `ğŸ•¸ï¸N_tech_profile`. Also create `ğŸ¦Budget_ğŸ•¸ï¸N` and link to `Project_ğŸ•¸ï¸N`.
    *   **Deliverables:** Rich `Project_ğŸ•¸ï¸N` and linked `ğŸ¦Budget_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** Set `priority_pheromone_strength_trailğŸ“ˆ` on `Î¼T_SYS_INIT_NEO4J_VERIFY_002`.
    *   **Success Criteria (ğŸš¦):** All specified metadata accurately stored and linked in ğŸ•¸ï¸Canvas.

### 1.2. Infrastructure Setup: ğŸ•¸ï¸Cognitive Canvas (Neo4j) Deep Verification & Schema Seeding (Î¼T_SYS_INIT_NEO4J_VERIFY_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§ cognitive_navigator` (assisted by `ğŸ›¡ï¸canvas_auditor` concepts if available)
    *   **Task Description:** Deeply verify Neo4j instance: connectivity, version, edition, license (if applicable), storage, performance baseline. Seed core schema indices & constraints.
    *   **Prerequisites:** Neo4j running, credentials `${env:NEO4J_...}` available.
    *   **Action (by `ğŸ§ cognitive_navigator` script/MCP):**
        1.  Connect & retrieve DBMS info (`CALL dbms.components()`). Log to `Infrastructure_ğŸ•¸ï¸N {type: 'Neo4jInstance'}`.
        2.  Retrieve storage metrics (`CALL dbms.queryJfr('list')`, `CALL dbms.metrics()`). Log to `Neo4jInstance_ğŸ•¸ï¸N` properties.
        3.  Execute a simple write/read/delete benchmark query. Log performance ms to `Neo4jInstance_ğŸ•¸ï¸N`.
        4.  Apply core indices/constraints for essential ğŸ•¸ï¸N labels defined in UMI (e.g., `MicroTask.Î¼T_id`, `Feature.feature_id`, `OperationalProfile.profile_name`, etc. from `umi_weaver.txt`). Ensure idempotency (IF NOT EXISTS).
    *   **Deliverables:** Detailed Neo4j instance profile in ğŸ•¸ï¸Canvas. Core schema constraints/indices applied.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_MCP_VERIFY_003`.
    *   **Success Criteria (ğŸš¦):** All verifications pass. Schema elements created successfully. Performance baseline recorded.

### 1.3. Infrastructure Setup: Core MCP Server Comprehensive Verification & Configuration Logging (Î¼T_SYS_INIT_MCP_VERIFY_003)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ›ï¸mcp_coordinator`
    *   **Task Description:** Comprehensively verify connectivity, version, and KEY configuration parameters of ALL essential MCP servers. Log this to individual `MCPInstance_ğŸ•¸ï¸N` nodes in ğŸ•¸ï¸Canvas.
    *   **Action (by `ğŸ›ï¸mcp_coordinator`):**
        *   For EACH MCP (`MemoryBankğŸ”¥`, `Context7`, `SequentialThinking`, `PerplexityAsk`, custom Neo4j MCP if exists):
            1.  Ping/Health Check: `use_mcp_tool [MCP_Name] get_health_status`.
            2.  Version Info: `use_mcp_tool [MCP_Name] get_version_info`.
            3.  Key Configs (if MCP API supports): `use_mcp_tool [MCP_Name] get_active_config_summary` (e.g., for MemoryBank: current DB backend, default TTL; for Context7: Upstash connection status).
            4.  Log all data to respective `MCPInstance_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas, linked to `Project_ğŸ•¸ï¸N`.
    *   **Deliverables:** Detailed status and config logs for all core MCPs in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_CLOUD_VERIFY_004`. Strong `warnâ—` on `Project_ğŸ•¸ï¸N` and relevant `MCPInstance_ğŸ•¸ï¸N` if any critical MCP is down/misconfigured.
    *   **Success Criteria (ğŸš¦):** All core MCPs fully operational and configurations logged.

### 1.4. Infrastructure Setup: Cloud Provider Service & Billing Verification (Î¼T_SYS_INIT_CLOUD_VERIFY_004)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `â˜ï¸cloud_architect` (using provider CLI tools via `execute_command` or provider-specific MCPs)
    *   **Task Description:** Verify access to required cloud services (e.g., Vertex AI for Gemini, Anthropic API endpoint), check current billing status/alerts, and log essential quota information for the primary LLMs into ğŸ•¸ï¸Canvas.
    *   **Action (by `â˜ï¸cloud_architect`):**
        1.  For each primary LLM provider (Google, Anthropic, OpenAI):
            *   Attempt a minimal, non-billable API call (e.g., list models) to verify authentication & service health.
            *   Programmatically check (if API allows) or link to manual check for current API quota usage and limits.
            *   Check billing account status/alerts.
        2.  Log results (service reachability, key quota limits like TokensPerMinute, RequestsPerMinute) to `CloudProviderService_ğŸ•¸ï¸N` (e.g., `GoogleVertexAI_ğŸ•¸ï¸N`) in ğŸ•¸ï¸Canvas, linked to `Project_ğŸ•¸ï¸N`.
    *   **Deliverables:** Cloud LLM service connectivity and key quota/billing status points logged in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_GIT_SETUP_005`. `warnâ—` if billing issues or near quota limits.
    *   **Success Criteria (ğŸš¦):** All essential cloud services verified. Critical info logged.

### 1.5. Version Control & Secure Project Workspace Setup (Î¼T_SYS_INIT_GIT_SETUP_005)
    *   **Assignee:** `ğŸŒŒWeaverCore` (using `execute_command`) -> `ğŸ›¡ï¸security_auditor` (for secret management advice)
    *   **Task Description:** Ensure robust Git setup: initialize repo, detailed `.gitignore` (from template in ğŸ•¸ï¸N_tech_profile or master template), establish branch strategy (e.g., `main`, `develop`, `feature/`), configure pre-commit hooks for basic linting/secret scanning (conceptual, may require manual setup of hooks or a script called by `execute_command`). Secure management of API keys/secrets (e.g., advise on `.env` use, SOPS, Vault - actual implementation external but audited).
    *   **Actions:**
        1.  `execute_command`: `git init`, `mkdir -p src tests docs scripts .roo .vscode .secrets` (conceptual for secrets, actual dir name may vary).
        2.  `ğŸ§ cognitive_navigator`: Fetch comprehensive `.gitignore` (`ğŸ•¸ï¸N_gitignore_template_advanced`) and write to project.
        3.  `ğŸ›¡ï¸security_auditor`: (Conceptually) Provides best-practice instructions for setting up `.env.example`, and for manually configuring a secrets management solution (like Doppler, Vault, or git-secret) externally. This task *documents* the chosen method.
        4.  `execute_command`: Set up basic Git branch structure: `git checkout -b develop`, `git checkout -b main`.
        5.  `execute_command` (if `ğŸ•¸ï¸N_tech_profile` has pre-commit hook config): `pre-commit install` (assumes `pre-commit` is installed and a `.pre-commit-config.yaml` is provided/generated based on `ğŸ•¸ï¸N_tech_profile`).
        6.  `execute_command`: `git add .gitignore README.md plan.md roo_modes_*.json umi_*.txt .env.example`
        7.  `execute_command`: `git commit -m "chore(project_weaver): Secure VCS workspace established with branch strategy, .gitignore, and secrets management protocol"`
    *   **Deliverables:** Secure Git repo. Advanced `.gitignore`. Documented secrets management strategy (`SecretsManagement_ğŸ•¸ï¸N_doc` in Canvas). Branching strategy defined (`BranchingStrategy_ğŸ•¸ï¸N_doc`). Pre-commit hooks conceptually active.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_PROFILE_LOCK_006`.
    *   **Success Criteria (ğŸš¦):** Git setup complete as specified. Secrets protocol documented.

### 1.6. Confirm, Lock, & Detail Active Operational & Tech Profiles (Î¼T_SYS_INIT_PROFILE_LOCK_006)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist`
    *   **Task Description:** `ğŸ§©meta_strategist` deeply analyzes project charter (from `Î¼T_SYS_INIT_CHARTER_001`) and current infrastructure status (from previous Î¼Ts). Confirms, refines, or selects the definitive `ğŸ•¸ï¸N_op_profile` and `ğŸ•¸ï¸N_tech_profile` for the project's initial development phase. All parameters of these selected profiles are explicitly logged into a `CurrentPhaseConfig_ğŸ•¸ï¸N` in Canvas for absolute clarity and auditability by other modes.
    *   **Action:**
        1.  `ğŸ§©meta_strategist` queries `ğŸ§ cognitive_navigator` for suitable profiles based on charter, potentially using `sequential_thinking` if choices have complex tradeoffs (e.g., new tech stack with unknown ğŸ²R vs. older stack with known limitations).
        2.  `ğŸ§©meta_strategist` makes a definitive selection.
        3.  `ğŸ§ cognitive_navigator` creates/updates `CurrentPhaseConfig_ğŸ•¸ï¸N` linked to `Project_ğŸ•¸ï¸N` and current `Phase_ğŸ•¸ï¸N` (e.g., `SYS_INIT_ECO_001_PhaseInstance_ğŸ•¸ï¸N`). This node will SNAPSHOT all critical parameters from the chosen OpProfile and TechProfile (e.g., `llm_for_coding: "claude-3.5-sonnet"`, `test_command: "pytest -s"`, `cost_threshold_Î¼T: 0.005`, etc.).
    *   **Deliverables:** Explicit `CurrentPhaseConfig_ğŸ•¸ï¸N` with all operational parameters locked and logged for the current phase in ğŸ•¸ï¸Canvas. Project now has unambiguous operational settings.
    *   **Pheromone Update:** Very strong `trailğŸ“ˆ` from `Project_ğŸ•¸ï¸N` to "Section 2: Feature Development - [FIRST_FEATURE_NAME]" primary pheromone. System is GO.
    *   **Success Criteria (ğŸš¦):** `CurrentPhaseConfig_ğŸ•¸ï¸N` exists, is fully populated with all relevant parameters, and linked correctly.

---

## ğŸ’» Section 2: Feature Development - [FEATURE_NAME_1] (Phase: `FEAT_DEV_001_[FeatureSlug]`)

**Parent Project ID (ğŸ•¸ï¸N_project_id):** `[ID_FROM_SECTION_1]`
**Active Configuration (CurrentPhaseConfig_ğŸ•¸ï¸N_id):** `[ID_FROM_Î¼T_SYS_INIT_PROFILE_LOCK_006]` (All modes will reference this for current OpProfile & TechProfile parameters)
**Pheromone Focus (trailğŸ“ˆ for this Feature Phase):** `develop_feature_[FeatureSlug]` (initially set by `ğŸ¤”reflection_engine` upon processing this section header by `ğŸŒŒWeaverCore`)
**Overall Feature Goal:** `[High-level description of the feature]`
**Feature ID (ğŸ•¸ï¸N_feature_id):** `[AUTO_GEN_FeatureSlug_001]` (Created by `ğŸŒŒWeaverCore` from section title, linked to `Project_ğŸ•¸ï¸N` and `CurrentPhaseConfig_ğŸ•¸ï¸N`)
**Estimated Story Points / Complexity (ğŸ²R_feature_complexity):** `[e.g., 5, 8, 13 based on initial assessment, can be an LLM estimate]` (Stored on `Feature_ğŸ•¸ï¸N`)

*(The `CurrentPhaseConfig_ğŸ•¸ï¸N_id` is critical; all modes operating on this feature will first query `ğŸ§ cognitive_navigator` for its parameters to know which LLMs to use, cost limits, testing rigor, specific tool commands from TechProfile, etc., ensuring consistent, profile-driven behavior without repeating these in every Î¼T prompt.)*

### 2.1. Deep Specification Elaboration & Validation Loop (Phase: `FEAT_SPEC_[FeatureSlug]_SUBPHASE_001`)

#### 2.1.1. Generate Initial Detailed Specifications (Î¼T_FEAT_[FeatureSlug]_SPEC_DRAFT_001.1)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ“spec_writer`
    *   **Input:** `Feature_ğŸ•¸ï¸N_id` (goal, context). Reference `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Task Description:** Generate detailed BDD scenarios (Given/When/Then), TDD test anchors (specific test case names and objectives), user stories (As a [user type], I want [action], so that [benefit]), non-functional requirements (performance, security from `Project_ğŸ•¸ï¸N_standards` or OpProfile), and data model sketches (if applicable for the feature). Query `ğŸ§ cognitive_navigator` for `ğŸ•¸ï¸P_related_specs` and `warnâ—`/`guideâœ¨` pheromones concerning similar features. Resolve ambiguities via UMI Ambiguity Protocol ğŸš© if necessary (could trigger sub-Î¼Ts like `Î¼T_FEAT_..._SPEC_AMBIGUITY_RESOLVE_X`).
    *   **Deliverables:** Draft `feature_spec_detail_ğŸ•¸ï¸N` created in ğŸ•¸ï¸Canvas, linked to `Feature_ğŸ•¸ï¸N`. Text file `docs/specs/[feature_slug]_spec_draft_v1.md`.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `Î¼T_FEAT_[FeatureSlug]_SPEC_REVIEW_001.2`.
    *   **Success Criteria (ğŸš¦):** Draft spec fully populated as per requirements. Stored.

#### 2.1.2. Automated Spec Review & Consistency Check (Î¼T_FEAT_[FeatureSlug]_SPEC_REVIEW_001.2)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (conceptually, using `sequential_thinking` or a dedicated "spec-analyzer" sub-mode if exists).
    *   **Input:** `feature_spec_detail_ğŸ•¸ï¸N` (draft).
    *   **Task Description:** Review draft spec for internal consistency, clarity, completeness against original Feature Goal, and alignment with project-wide non-functional requirements (from `Project_ğŸ•¸ï¸N_standards`). Check for conflicting requirements or overlaps with existing `feature_spec_ğŸ•¸ï¸N`s in Canvas (via `ğŸ§ cognitive_navigator`).
    *   **Deliverables:** `SpecReviewReport_ğŸ•¸ï¸N` linked to `feature_spec_detail_ğŸ•¸ï¸N`. List of issues/suggestions.
    *   **Pheromone Update:** If issues, `warnâ—` on draft spec & `trailğŸ“ˆ` back to `ğŸ“spec_writer` for revision `Î¼T_FEAT_..._SPEC_REVISE_X`. If clear, `trailğŸ“ˆ` to architecture or first code unit.
    *   **Success Criteria (ğŸš¦):** Review report generated. Spec status updated to `Validated` or `NeedsRevision`.

*(Iterate SPEC_DRAFT and SPEC_REVIEW Î¼Ts if revisions are needed until SpecReviewReport_ğŸ•¸ï¸N is PASS)*

### 2.2. Detailed Architectural Breakdown & Risk Analysis (Phase: `FEAT_ARCH_[FeatureSlug]_SUBPHASE_002`) - *Conditional as per OpProfile*

#### 2.2.1. Generate Architectural Options & Trade-offs (Î¼T_FEAT_[FeatureSlug]_ARCH_OPTIONS_002.1)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ—ï¸architect`
    *   **Input:** Validated `feature_spec_detail_ğŸ•¸ï¸N`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for design patterns allowed, cost constraints). `Project_ğŸ•¸ï¸N_arch_principles`.
    *   **Task Description:** For the feature, propose 1-3 high-level architectural approaches (e.g., microservice vs. monolithic module, event-driven vs. request-response). Query `ğŸ§ cognitive_navigator` for existing `ğŸ•¸ï¸P_arch_patterns_used_in_project`, relevant `guideâœ¨`/`warnâ—` pheromones on patterns, and `ğŸ²R_scores` of components to be interacted with. Document trade-offs (performance, complexity, cost, security) for each option.
    *   **Deliverables:** `ArchOptionsReport_ğŸ•¸ï¸N` linked to `feature_spec_detail_ğŸ•¸ï¸N`, containing multiple `ArchOption_ğŸ•¸ï¸N` sketches.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `Î¼T_FEAT_[FeatureSlug]_ARCH_SELECT_002.2`.
    *   **Success Criteria (ğŸš¦):** Report with distinct options and trade-offs generated.

#### 2.2.2. Select & Detail Chosen Architecture (Î¼T_FEAT_[FeatureSlug]_ARCH_SELECT_002.2)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (or `ğŸ—ï¸architect` if delegated by OpProfile, with `sequential_thinking` for decision logic).
    *   **Input:** `ArchOptionsReport_ğŸ•¸ï¸N`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for strategic fit). Feature ğŸ²R.
    *   **Task Description:** Analyze options. Select the optimal architecture. Fully detail it: define all new/modified `component_ğŸ•¸ï¸N`s, their responsibilities, APIs (`Interface_ğŸ•¸ï¸N`), data models (`DataModel_ğŸ•¸ï¸N`), and `ğŸ•¸ï¸R_interactions` (dependencies, data flows). Document ADR.
    *   **Cost Justification docsğŸ’°:** If chosen arch is high-cost.
    *   **Deliverables:** Final `architecture_design_ğŸ•¸ï¸N` linked to `feature_spec_detail_ğŸ•¸ï¸N`. ADR file. Updated component/interface/datamodel ğŸ•¸ï¸Ns in Canvas.
    *   **Pheromone Update:** Strong `guideâœ¨` from chosen `architecture_design_ğŸ•¸ï¸N` to various `component_ğŸ•¸ï¸N`s, guiding subsequent coding Î¼Tasks. `trailğŸ“ˆ` to first coding Î¼T.
    *   **Success Criteria (ğŸš¦):** Chosen architecture fully detailed, documented, and represented in ğŸ•¸ï¸Canvas.

### 2.3. Iterative Code & Test Implementation Loop (Phase: `FEAT_CODE_TEST_[FeatureSlug]_SUBPHASE_003`)
*(For each `component_ğŸ•¸ï¸N` or logical code unit identified in the architecture/spec, a series of Î¼Tasks is executed)*

#### **Micro-Loop for Component/Unit: `[ComponentNameOrUnitSlug]`**

##### 2.3.[X].1. Define Test Cases (TDD - Tests First) (Î¼T_FEAT_[FeatureSlug]_TESTDEF_[UnitSlug]_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ“spec_writer` or `âš¡coder` (per OpProfile: strict TDD vs. BDD-to-Test).
    *   **Input:** Unit requirements from `feature_spec_detail_ğŸ•¸ï¸N` / `architecture_design_ğŸ•¸ï¸N`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (`ğŸ•¸ï¸N_tech_profile` for test framework).
    *   **Task Description:** Write detailed, executable (but initially failing) test cases/stubs for `[ComponentNameOrUnitSlug]` in `tests/[path/to/test_unit.ext]`. Cover positive, negative, edge cases.
    *   **Deliverables:** Test code file created/updated. `TestCase_ğŸ•¸ï¸N` (or `TestSuite_ğŸ•¸ï¸N`) created in Canvas, linked to the conceptual `CodeModule_ğŸ•¸ï¸N` for this unit. TDD Status for this unit on `ğŸš¦quality_gatekeeper` prep: `DEFINED`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_CODEIMP_` for this unit. Strong `guideâœ¨` from tests to code.
    *   **Success Criteria (ğŸš¦):** Test file and runnable (failing) stubs created. Test definitions logged in Canvas.

##### 2.3.[X].2. Implement Code Unit (Î¼T_FEAT_[FeatureSlug]_CODEIMP_[UnitSlug]_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `âš¡coder`
    *   **Input:** Unit requirements, defined tests (`TestCase_ğŸ•¸ï¸N`). `CurrentPhaseConfig_ğŸ•¸ï¸N_id`. Relevant `guideâœ¨`/`warnâ—` pheromones.
    *   **Task Description:** Implement code for `[ComponentNameOrUnitSlug]` in `src/[path/to/code_unit.ext]` to make defined tests pass. Adhere to `ğŸ•¸ï¸N_tech_profile`.
    *   **Research:** As needed, budgeted by OpProfile, via `ğŸ§ cognitive_navigator` or `ğŸ”¬github_researcher`.
    *   **Deliverables:** Source code written/updated. `CodeModule_ğŸ•¸ï¸N` / `Function_ğŸ•¸ï¸N` detailed in Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_QUALCHK_` for this unit.
    *   **Success Criteria (ğŸš¦):** Code implemented. (Subject to Quality Gate).

##### 2.3.[X].3. Quality Gate Check for Code Unit (Î¼T_FEAT_[FeatureSlug]_QUALCHK_[UnitSlug]_003) - MANDATORY
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸš¦quality_gatekeeper`
    *   **Input:** Path to code, corresponding test definitions (`TestCase_ğŸ•¸ï¸N` from Canvas), `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (`ğŸ•¸ï¸N_tech_profile` for linters/standards).
    *   **Task Description:** Perform full static analysis, compliance, style checks. **Re-verify test definitions against implemented code structure to ensure coverage (not just existence).**
    *   **Deliverables:** PASS/FAIL. `quality_report_ğŸ•¸ï¸N` for this unit.
    *   **Pheromone Update:** If FAIL, `warnâ—` on `_CODEIMP_` Î¼T, `trailğŸ“ˆ` to `âš¡coder` for rework. If PASS, `trailğŸ“ˆ` to `_TESTEXEC_`.
    *   **Success Criteria (ğŸš¦):** All checks PASS, including TDD alignment of tests to code.

##### 2.3.[X].4. Execute Unit Tests (Î¼T_FEAT_[FeatureSlug]_TESTEXEC_[UnitSlug]_004)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> Appropriate Tester (from TechProfile, e.g., `ğŸ™ï¸chicago_tester`).
    *   **Input:** Test files, source code. Test command from `ğŸ•¸ï¸N_tech_profile`.
    *   **Task Description:** Execute unit tests for `[ComponentNameOrUnitSlug]`.
    *   **Deliverables:** `TestRun_ğŸ•¸ï¸N` (PASS/FAIL, coverage) in Canvas.
    *   **Pheromone Update:** If FAIL, `warnâ—` on code/tests, `trailğŸ“ˆ` to `ğŸ”debugger`. If PASS, `guideâœ¨` on `CodeModule_ğŸ•¸ï¸N`. Increment `trailğŸ“ˆ` for next code unit or feature integration if this is the last unit.
    *   **Success Criteria (ğŸš¦):** All unit tests for this unit PASS. Coverage meets OpProfile threshold.

##### 2.3.[X].5. Debug Unit (If Tests Fail) (Î¼T_FEAT_[FeatureSlug]_DEBUG_[UnitSlug]_005) - *Conditional*
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ”debugger`
    *   **Input:** Failed `TestRun_ğŸ•¸ï¸N`, source code `CodeModule_ğŸ•¸ï¸N`, relevant error context `warnâ—` pheromones. OpProfile (for debug depth).
    *   **Task Description:** Diagnose and propose fix for failed unit tests.
    *   **Deliverables:** `DebugReport_ğŸ•¸ï¸N` with root cause and suggested fix. This fix then goes through a new mini `_CODEIMP_` -> `_QUALCHK_` -> `_TESTEXEC_` cycle.
    *   **Pheromone Update:** `ğŸ¤”reflection_engine/scribe` logs debug path. If successful, `warnâ—` on original error cause may be weakened.
    *   **Success Criteria (ğŸš¦):** Root cause identified. Actionable fix proposed.

*(End of Micro-Loop for Component/Unit. Repeat 2.3.[X].1 to 2.3.[X].5 for ALL units in the feature.)*

### 2.4. Feature Integration, System & E2E Testing Loop (Phase: `FEAT_INTEGRATE_TEST_[FeatureSlug]_SUBPHASE_004`)

#### 2.4.1. Define Feature Integration Test Plan (Î¼T_FEAT_[FeatureSlug]_INTG_PLAN_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ—ï¸architect` or senior `ğŸ§ªtester-definer`.
    *   **Input:** All PASSING `CodeModule_ğŸ•¸ï¸N`s for this feature, `architecture_design_ğŸ•¸ï¸N`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Task Description:** Define test scenarios for interactions BETWEEN components of this feature, and between this feature and existing major system components (identified via `ğŸ§ cognitive_navigator` from `ğŸ•¸ï¸P_project_dependency_graph`). Consider high ğŸ²R interaction points.
    *   **Deliverables:** `IntegrationTestPlan_ğŸ•¸ï¸N` in Canvas, linked to `Feature_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_INTG_IMPL_`.
    *   **Success Criteria (ğŸš¦):** Comprehensive integration test plan defined.

#### 2.4.2. Implement Integration Tests (Î¼T_FEAT_[FeatureSlug]_INTG_IMPL_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `âš¡coder` or `ğŸ§ªtester-implementer`.
    *   **Input:** `IntegrationTestPlan_ğŸ•¸ï¸N`. `ğŸ•¸ï¸N_tech_profile` (for integration testing tools/frameworks).
    *   **Task Description:** Implement the integration tests.
    *   **Deliverables:** `IntegrationTestSuite_ğŸ•¸ï¸N` code and Canvas representation.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_INTG_EXEC_`.
    *   **Success Criteria (ğŸš¦):** Tests implemented.

#### 2.4.3. Execute Integration Tests (Î¼T_FEAT_[FeatureSlug]_INTG_EXEC_003)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> Specialized `ğŸ§ªintegration_tester` (if mode exists) or a general Tester.
    *   **Input:** `IntegrationTestSuite_ğŸ•¸ï¸N`. Staging environment context (if applicable from TechProfile).
    *   **Task Description:** Run all integration tests for the feature.
    *   **Deliverables:** `IntegrationTestRun_ğŸ•¸ï¸N` results (PASS/FAIL) in Canvas.
    *   **Pheromone Update:** If FAIL, `warnâ—` on feature, `trailğŸ“ˆ` to `ğŸ”debugger`. If PASS, strong `guideâœ¨` on `Feature_ğŸ•¸ï¸N` (stability).
    *   **Success Criteria (ğŸš¦):** All integration tests PASS.

#### 2.4.4. Define E2E User Acceptance Tests (UAT) (Î¼T_FEAT_[FeatureSlug]_UAT_DEF_004) - *May involve `ğŸ“spec_writer` looking at user stories.*
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ“spec_writer` or dedicated `ğŸ§ªuat_designer`.
    *   **Input:** Original `feature_spec_detail_ğŸ•¸ï¸N` (user stories). `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Task Description:** Define E2E test scenarios from a user perspective for the completed feature.
    *   **Deliverables:** `UAT_Scenario_ğŸ•¸ï¸N_Set` in Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_UAT_EXEC_`.
    *   **Success Criteria (ğŸš¦):** UAT scenarios defined.

#### 2.4.5. Execute E2E / UAT (Î¼T_FEAT_[FeatureSlug]_UAT_EXEC_005) - *May need browser automation tools or simulated user interaction MCP if GUI.*
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§ªe2e_tester` (conceptual mode using tools like Selenium/Playwright via `execute_command` or MCP).
    *   **Input:** `UAT_Scenario_ğŸ•¸ï¸N_Set`. Deployed feature (e.g., on a staging env).
    *   **Task Description:** Execute E2E user acceptance tests.
    *   **Deliverables:** `UAT_Run_ğŸ•¸ï¸N` results (PASS/FAIL) in Canvas.
    *   **Pheromone Update:** If FAIL, `warnâ—` on feature, `trailğŸ“ˆ` to `ğŸ”debugger`. If PASS, `trailğŸ“ˆ` on `Feature_ğŸ•¸ï¸N` for `_DOC_` or `_DEPLOY_READY_` status.
    *   **Success Criteria (ğŸš¦):** All UAT scenarios PASS.

### 2.5. Documentation Generation & Review (Phase: `FEAT_DOC_[FeatureSlug]_SUBPHASE_005`)

#### 2.5.1. Draft Technical & User Documentation (Î¼T_FEAT_[FeatureSlug]_DOC_DRAFT_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ“šdoc_writer`
    *   **Input:** PASSING `Feature_ğŸ•¸ï¸N` (with all linked specs, arch, code, tests). `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for doc style/detail). `guideâœ¨` pheromones on urgent doc needs.
    *   **Task Description:** Create technical documentation (API docs, module descriptions) and user-facing documentation (how-to guides, feature explanations) for `[FEATURE_NAME_1]`. Query `ğŸ§ cognitive_navigator` for existing `ğŸ•¸ï¸N_doc_template` or `ğŸ•¸ï¸N_style_guide`.
    *   **Deliverables:** Draft `TechnicalDoc_ğŸ•¸ï¸N` and `UserDoc_ğŸ•¸ï¸N` linked to `Feature_ğŸ•¸ï¸N` in Canvas. Files in `docs/feature_slug/`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_DOC_REVIEW_`.
    *   **Success Criteria (ğŸš¦):** Draft documents created, cover essential aspects.

#### 2.5.2. Documentation Review (Î¼T_FEAT_[FeatureSlug]_DOC_REVIEW_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (conceptually, using `sequential_thinking` or a "doc-reviewer" sub-mode).
    *   **Input:** Draft `TechnicalDoc_ğŸ•¸ï¸N` and `UserDoc_ğŸ•¸ï¸N`.
    *   **Task Description:** Review for clarity, accuracy, completeness, and style guide adherence.
    *   **Deliverables:** `DocReviewReport_ğŸ•¸ï¸N` for each doc type.
    *   **Pheromone Update:** If issues, `warnâ—` on draft docs, `trailğŸ“ˆ` back to `ğŸ“šdoc_writer` for revision. If clear, `Feature_ğŸ•¸ï¸N` `status_pheromone` becomes `READY_FOR_RELEASE_REVIEW`.
    *   **Success Criteria (ğŸš¦):** Docs reviewed, approved.

---

## ğŸš€ Section 3: Release Preparation & Deployment - [RELEASE_VERSION_X.Y.Z] (Phase: `REL_PREP_DEPLOY_XYZ`)

**Pheromone Focus (trailğŸ“ˆ for this Phase):** `release_candidate_XYZ_deployment_pipeline`
**Objective:** Package all completed and verified features, perform final release testing, and deploy `[RELEASE_VERSION_X.Y.Z]` to target environment(s) according to OpProfile strategy.

### 3.1. Release Candidate Branching & Versioning (Î¼T_REL_BRANCH_VERSION_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` (using `execute_command` for Git).
    *   **Input:** List of `Feature_ğŸ•¸ï¸N`s tagged `READY_FOR_RELEASE_REVIEW`. Proposed version `X.Y.Z`.
    *   **Task Description:** Create a `release/X.Y.Z` branch from `develop`. Merge completed features into it. Tag the release candidate. Update version numbers in project files (e.g., `setup.py`, `package.json` via `âš¡coder` with specific Î¼T).
    *   **Deliverables:** `release/X.Y.Z` branch created. `vX.Y.Z-rc1` tag created. Version numbers updated. `ReleaseCandidate_ğŸ•¸ï¸N` in Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `_REL_BUILD_ARTIFACT_`.
    *   **Success Criteria (ğŸš¦):** Branch & tag exist. Version files updated.

### 3.2. Build Release Artifacts (Î¼T_REL_BUILD_ARTIFACT_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ³docker_engineer` or `â˜ï¸cloud_architect` (depending on TechProfile build system).
    *   **Input:** `release/X.Y.Z` branch. `ğŸ•¸ï¸N_tech_profile` (for build commands, Dockerfile paths, artifact repo info).
    *   **Task Description:** Build release artifacts (e.g., Docker images, JARs, WHEELs). Push to artifact repository.
    *   **Deliverables:** `Artifact_ğŸ•¸ï¸N` (with link to repo path/tag) in Canvas. Artifacts available in repository.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_REL_STAGING_DEPLOY_`.
    *   **Success Criteria (ğŸš¦):** Build successful. Artifacts published.

### 3.3. Deploy to Staging Environment (Î¼T_REL_STAGING_DEPLOY_003)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `â˜ï¸cloud_architect`
    *   **Input:** `Artifact_ğŸ•¸ï¸N`. Staging environment config from `ğŸ•¸ï¸N_tech_profile` or specialized `Environment_ğŸ•¸ï¸N`.
    *   **Task Description:** Deploy the release candidate artifact to the staging environment.
    *   **Deliverables:** Staging deployment successful. `DeploymentLog_ğŸ•¸ï¸N` in Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_REL_STAGING_TEST_`.
    *   **Success Criteria (ğŸš¦):** Deployment successful. Application healthy in staging.

### 3.4. Execute Full Regression & Smoke Tests on Staging (Î¼T_REL_STAGING_TEST_004)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§ªcomprehensive_tester_suite_runner` (conceptual mode running ALL relevant test suites: Unit, Integration, E2E/UAT).
    *   **Input:** Staging environment URL/access. All test suites linked to features in this release.
    *   **Task Description:** Run the full battery of automated tests against the staging deployment.
    *   **Deliverables:** `MasterTestReport_ğŸ•¸ï¸N` for staging in Canvas.
    *   **Pheromone Update:** If FAIL, strong `warnâ—` on `ReleaseCandidate_ğŸ•¸ï¸N`, `trailğŸ“ˆ` to `ğŸ”debugger` (hotfix on release branch). If PASS, `status_pheromone` on `ReleaseCandidate_ğŸ•¸ï¸N` becomes `READY_FOR_PROD_APPROVAL`.
    *   **Success Criteria (ğŸš¦):** All tests PASS on staging.

### 3.5. Production Deployment Approval Gate (Î¼T_REL_PROD_APPROVAL_005) - *May require human approval based on OpProfile / Risk*
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (with possible human interaction step based on OpProfile `prod_deployment_approval_policy`).
    *   **Input:** `ReleaseCandidate_ğŸ•¸ï¸N` status (`READY_FOR_PROD_APPROVAL`), `MasterTestReport_ğŸ•¸ï¸N` for staging. Associated ğŸ²R. Current `ğŸ¦project_budget_ğŸ•¸ï¸N`.
    *   **Task Description:** Review release candidate readiness. If OpProfile policy is `manual_approval_required`, PING human stakeholder via notification mechanism. Otherwise, `ğŸ§©meta_strategist` makes automated GO/NO-GO based on test results, remaining budget, and overall project ğŸ²R.
    *   **Deliverables:** `ProductionDeploymentApproval_ğŸ•¸ï¸N` (Approved/Rejected) in Canvas.
    *   **Pheromone Update:** If Approved, `trailğŸ“ˆ` to `_REL_PROD_DEPLOY_`. If Rejected, `warnâ—` and `trailğŸ“ˆ` to debugging/rollback planning.
    *   **Success Criteria (ğŸš¦):** Explicit approval (automated or manual) logged.

### 3.6. Deploy to Production (Î¼T_REL_PROD_DEPLOY_006)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `â˜ï¸cloud_architect`
    *   **Input:** Approved `ReleaseCandidate_ğŸ•¸ï¸N` / `Artifact_ğŸ•¸ï¸N`. Production environment config. OpProfile (for deployment strategy: blue/green, canary, rolling).
    *   **Task Description:** Deploy to production using specified strategy. Execute smoke tests post-deployment.
    *   **Deliverables:** Production deployment successful. `ProdDeploymentLog_ğŸ•¸ï¸N` in Canvas.
    *   **Pheromone Update:** `status_pheromone` on `Release_Version_XYZ_ğŸ•¸ï¸N` (new node for actual release) becomes `LIVE`. `trailğŸ“ˆ` for post-deployment monitoring.
    *   **Success Criteria (ğŸš¦):** Deployment successful. Critical smoke tests pass in production.

### 3.7. Post-Deployment Monitoring & Initial Feedback Loop (Î¼T_REL_POST_MONITOR_007)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ“Šmonitor_setup_agent` (conceptual: configures monitoring tools like Prometheus/Grafana/Sentry via scripts/APIs) & `ğŸ¤”reflection_engine` (to watch for early `warnâ—` pheromones).
    *   **Input:** `Release_Version_XYZ_ğŸ•¸ï¸N`. Monitoring tool configs from TechProfile.
    *   **Task Description:** Ensure monitoring dashboards are active for the new release. `ğŸ¤”reflection_engine` monitors initial error rates, performance metrics from logging systems (conceptually fed into Canvas) for any immediate negative `trailğŸ“ˆ` or new `warnâ—` pheromones.
    *   **Deliverables:** Monitoring confirmed active. Initial (e.g., 1 hour) stability report summary `PostReleaseHealth_ğŸ•¸ï¸N` in Canvas.
    *   **Pheromone Update:** If anomalies, critical `warnâ—` on `Release_Version_XYZ_ğŸ•¸ï¸N`. `trailğŸ“ˆ` for normal operations or rollback planning if needed.
    *   **Success Criteria (ğŸš¦):** Monitoring active. No critical immediate post-deployment failures.

---

## ğŸ”§ Section 4: System Operations & Autonomous Maintenance (Phase: `SYS_OPS_MAINTAIN_ONGOING`)

**Pheromone Focus (trailğŸ“ˆ types):** `system_maintenance`, `security_audit_cycle`, `refactor_opportunity_discovery`, `canvas_health_check`, `umi_evolution_experiment`
*(These are ongoing, cyclically triggered, or event-driven Î¼Task families managed primarily by `ğŸ§©meta_strategist` and `ğŸ¤”reflection_engine`.)*

### 4.1. Scheduled Tech Horizon Scanning Cycle (Î¼T_MAINT_TECHSCAN_CYCLE_[Date])
    *   (As defined in `ğŸ¤”reflection_engine` and UMI section XII.12.4)

### 4.2. Scheduled Cognitive Canvas Integrity Audit Cycle (Î¼T_MAINT_CANVAS_AUDIT_CYCLE_[Date])
    *   (As defined in `ğŸ¤”reflection_engine` and UMI section XIII.13.1)

### 4.3. Scheduled UMI/Mode Effectiveness Review & AMO Proposal Cycle (Î¼T_MAINT_AMO_REVIEW_CYCLE_[Date])
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ¤”reflection_engine` -> `ğŸ§©meta_strategist`
    *   **Task Description:** `ğŸ¤”reflection_engine` performs deep analysis of ğŸ•¸ï¸Canvas for UMI/Mode effectiveness over last N Î¼Tasks or time period. Generates `ğŸ•¸ï¸N_improvement_hypothesis`. `ğŸ§©meta_strategist` reviews hypotheses, prioritizes, and schedules A/B tests or direct updates (if high confidence and low risk).
    *   **Deliverables:** `AMO_Report_ğŸ•¸ï¸N`. New/updated `ğŸ•¸ï¸N_improvement_hypothesis`. Log of A/B tests planned/executed.
    *   **Success Criteria (ğŸš¦):** Review cycle completed. Actionable hypotheses generated/tested.

### 4.4. Proactive Refactoring Identification & Planning Cycle (Î¼T_MAINT_REFACTOR_ID_CYCLE_[Date])
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ¤”reflection_engine` -> `ğŸ—ï¸architect`
    *   **Task Description:** `ğŸ¤”reflection_engine` scans ğŸ•¸ï¸Canvas for technical debt indicators (high complexity `CodeModule_ğŸ•¸ï¸N`, frequent bugs in an area `ğŸ•¸ï¸P_bug_cluster`, strong `technical_debt_warnâ—` pheromones). If candidates found, `ğŸ—ï¸architect` is tasked to create a `RefactoringPlan_ğŸ•¸ï¸N`. Approved plans become backlog features.
    *   **Deliverables:** `RefactoringCandidateReport_ğŸ•¸ï¸N`. Potential `RefactoringPlan_ğŸ•¸ï¸N`s.
    *   **Success Criteria (ğŸš¦):** Cycle completed. Candidates identified. High-priority refactoring plans created.

### 4.5. Budget Review & OpProfile Tuning Cycle (Î¼T_MAINT_BUDGET_REVIEW_CYCLE_[Date])
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (consulting `ğŸ’°cost_optimizer` analysis)
    *   **Input:** `ğŸ¦project_budget_ğŸ•¸ï¸N` current status, burn rate forecast from `ğŸ§ cognitive_navigator`, `Project_ğŸ•¸ï¸N` milestone dates.
    *   **Task Description:** Review budget status against project progress. Tune active `ğŸ•¸ï¸N_op_profile` parameters (e.g., default LLM choice, cost thresholds) to align with remaining budget and timelines. Consider shifting to/from `ULTRA_COST_SAVE_HIBERNATE` if necessary.
    *   **Deliverables:** `BudgetReviewReport_ğŸ•¸ï¸N`. Updated active `ğŸ•¸ï¸N_op_profile` parameters in Canvas.
    *   **Success Criteria (ğŸš¦):** Review complete. OpProfile tuned to current fiscal reality.

---

## ğŸ“– Appendix A: Definitions & Conventions

*   **[PROJECT_NAME], [FeatureSlug], etc.:** Placeholders to be filled.
*   **ğŸ•¸ï¸N, ğŸ•¸ï¸R, ğŸ•¸ï¸P:** Refer to Nodes, Relationships, and Paths in the Cognitive Canvas.
*   **trailğŸ“ˆ, guideâœ¨, warnâ—:** Pheromone types, typically as properties on ğŸ•¸ï¸N or distinct ğŸ•¸ï¸R types.
*   **ğŸ²R:** Risk Score (property or linked ğŸ•¸ï¸N).
*   **ğŸš¦:** Success criteria / Quality Gate status indicator.
*   **ğŸ”¥:** MemoryBank MCP.
*   **ğŸ¦:** Budget / Cost considerations / Status (e.g., a property on `Project_ğŸ•¸ï¸N`).
*   **ğŸ’¡:** Generative Innovation Protocol.
*   **ğŸ“¡:** Tech Horizon Scanning.
*   **ğŸ›¡ï¸:** Cognitive Canvas Integrity.
*   **ğŸš©:** Ambiguity Flag.
*   **docsğŸ’°:** Cost Justification documentation (could be a `Justification_ğŸ•¸ï¸N` linked to an expensive Î¼T).
*   **Î¼T_Phase_ShortName_Seq[.SubSeq]:** Micro-task naming for traceability.
*   **OpProfile / TechProfile:** Active Operational (`ğŸ•¸ï¸N_op_profile`) and Technology Stack (`ğŸ•¸ï¸N_tech_profile`) Profiles, defined in and queried from ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`, guide all mode behavior. Their parameters are SNAPSHOTTED into a `CurrentPhaseConfig_ğŸ•¸ï¸N` for auditable execution context of a specific phase.

---
