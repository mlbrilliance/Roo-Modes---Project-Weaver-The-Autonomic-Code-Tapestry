# Project Weaver Plan: [PROJECT_NAME] - Autonomic Development Blueprint  weaver_plan_v1.1 (ULTRA_GRANULAR_EXPLICIT_STRATEGY_EDITION)

**Project ID (ğŸ•¸ï¸N_project_id):** `[AUTO_GENERATED_OR_USER_DEFINED_UNIQUE_ID]`
**Project Weaver Version Context:** `UMI v9.1 - Explicit Autonomic Weaver`
**Date Created:** `YYYY-MM-DD`
**Last Updated:** `YYYY-MM-DD`
**Overall Goal:** `[Clear, concise statement of what this project aims to achieve. E.g., "Develop a scalable, secure, multi-tenant SaaS platform for real-time collaborative document editing with AI-powered suggestions and version control."]`

---

## ğŸ¯ Section 1: Project Initialization & Ecosystem Setup (Phase: `SYS_INIT_ECO_001`)

**Pheromone Focus (Initial trailğŸ“ˆ for this Phase):** `ecosystem_bootstrap_critical_path`
**Active Configuration (CurrentPhaseConfig_ğŸ•¸ï¸N_id for this section):** `[ID_TO_BE_CREATED_IN_Î¼T_SYS_INIT_PROFILE_LOCK_005]` (Initially, modes use fallback/default until this is locked)
**Objective:** Establish, verify, and document all foundational infrastructure, services, security baselines, core ğŸ•¸ï¸Cognitive Canvas entries, and initial project governance, resulting in a locked `CurrentPhaseConfig_ğŸ•¸ï¸N` for subsequent phases.

### 1.1. Define Core Project Charter in ğŸ•¸ï¸Cognitive Canvas (Î¼T_SYS_INIT_CHARTER_001)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` -> `ğŸ§ cognitive_navigator`
    *   **Task Description:** Create/Update the primary `Project_ğŸ•¸ï¸N` in the ğŸ•¸ï¸Cognitive Canvas with comprehensive charter metadata.
    *   **Input Data:**
        *   `project_name`: "[PROJECT_NAME]"
        *   `project_vision`: "[Longer-term vision for the project beyond initial goal]"
        *   `project_goal_primary`: "[Overall Goal Statement from above]"
        *   `project_scope_inclusions`: "[Bulleted list of key things IN scope]"
        *   `project_scope_exclusions`: "[Bulleted list of key things OUT of scope]"
        *   `stakeholders_primary_ğŸ•¸ï¸N_ids`: `["USER_STAKEHOLDER_GROUP_01", "BUSINESS_OWNER_01"]` (Conceptual, link to stakeholder ğŸ•¸ï¸Ns if they exist)
        *   `initial_op_profile_preference`: "[e.g., MAX_QUALITY_SETUP, BALANCED_INIT]"
        *   `initial_tech_profile_preference`: "[e.g., PYTHON_FASTAPI_POSTGRES_REACT_DOCKER_AWS, JAVA_SPRING_MYSQL_ANGULAR_K8S_AZURE]"
        *   `estimated_complexity_ğŸ²R_initial`: `[Low/Medium/High/VeryHigh]`
        *   `target_milestone_1_date_estimate`: `[YYYY-MM-DD]`
        *   `budget_code_ğŸ¦_initial_allocation`: `[Currency Amount or Computational Units]`
    *   **Action (Conceptual, by `ğŸ§ cognitive_navigator`):**
        ```cypher
        MERGE (p:Project {project_id: $projectId})
        ON CREATE SET p.name = $projectName, p.goal = $projectGoal, p.vision = $projectVision, p.scope_inclusions = $scopeInclusions, p.scope_exclusions = $scopeExclusions, p.initial_complexity_dice_r = $estimatedComplexityDiceR, p.target_milestone_1_date = $targetMilestoneDate, p.status = 'INITIALIZING', p.creation_date = datetime(), p.umi_version_context = 'UMI v9.1'
        ON MATCH SET p.name = $projectName, p.goal = $projectGoal, p.vision = $projectVision, p.scope_inclusions = $scopeInclusions, p.scope_exclusions = $scopeExclusions, p.initial_complexity_dice_r = $estimatedComplexityDiceR, p.target_milestone_1_date = $targetMilestoneDate, p.last_updated = datetime()
        WITH p
        MERGE (b:Budget {project_id: $projectId, type: "INITIAL_ALLOCATION"})
        ON CREATE SET b.amount = $initialBudget, b.currency_or_units = $budgetUnits, b.allocation_date = datetime()
        MERGE (p)-[:HAS_BUDGET]->(b)
        // Conceptual linking to stakeholder groups if those nodes exist
        // FOREACH (stakeholder_id IN $stakeholderIds |
        //   MATCH (s:StakeholderGroup {id: stakeholder_id})
        //   MERGE (p)-[:HAS_PRIMARY_STAKEHOLDER]->(s)
        // )
        RETURN p.project_id AS projectNodeId, b.amount AS budgetAmount;
        ```
    *   **Deliverables:** Rich `Project_ğŸ•¸ï¸N` and linked `ğŸ¦Budget_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas, including all specified metadata.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** Set `priority_pheromone_strength_trailğŸ“ˆ` property on `Project_ğŸ•¸ï¸N` to moderate. Set strong `trailğŸ“ˆ` to `Î¼T_SYS_INIT_NEO4J_VERIFY_002`.
    *   **Success Criteria (ğŸš¦):** All specified metadata accurately stored and linked in ğŸ•¸ï¸Canvas as verified by a read-back query.

### 1.2. Infrastructure Setup: ğŸ•¸ï¸Cognitive Canvas (Neo4j) Deep Verification & Schema Seeding (Î¼T_SYS_INIT_NEO4J_VERIFY_002)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§ cognitive_navigator` (assisted by `ğŸ›¡ï¸canvas_auditor` logic for verification step)
    *   **Task Description:** Deeply verify Neo4j instance: connectivity, version, edition, license status, available storage, basic performance metrics. Seed core schema indices & constraints defined in the UMI's conceptual data model.
    *   **Prerequisites:** Neo4j instance running and accessible with credentials `${env:NEO4J_URI}`, `${env:NEO4J_USER}`, `${env:NEO4J_PASSWORD}`.
    *   **Action (by `ğŸ§ cognitive_navigator` script/MCP call):**
        1.  Establish connection. Log success/failure.
        2.  Execute `CALL dbms.components() YIELD name, versions, edition RETURN name, versions, edition;`. Store `versions` and `edition` on an `Infrastructure_ğŸ•¸ï¸N {type: 'Neo4jInstance', project_id: $projectId}`.
        3.  Execute `CALL dbms.metrics() WHERE name STARTS WITH 'neo4j.store.size.' RETURN name, value;`. Log key storage metrics (total size, free space) to the `Neo4jInstance_ğŸ•¸ï¸N`.
        4.  Execute a standardized simple CRUD benchmark (e.g., create 100 nodes, create 100 relationships, read 100 nodes, delete them). Record average timings for each op on `Neo4jInstance_ğŸ•¸ï¸N` as `benchmark_create_ms`, `benchmark_read_ms`, etc.
        5.  Apply core indices and constraints (idempotently using `IF NOT EXISTS`):
            ```cypher
            CREATE CONSTRAINT constraint_Î¼T_id IF NOT EXISTS FOR (n:MicroTask) REQUIRE n.Î¼T_id IS UNIQUE;
            CREATE CONSTRAINT constraint_feature_id IF NOT EXISTS FOR (n:Feature) REQUIRE n.feature_id IS UNIQUE;
            CREATE CONSTRAINT constraint_op_profile_name IF NOT EXISTS FOR (n:OperationalProfile) REQUIRE n.profile_name IS UNIQUE;
            CREATE CONSTRAINT constraint_tech_profile_name IF NOT EXISTS FOR (n:TechnologyStackProfile) REQUIRE n.profile_name IS UNIQUE;
            CREATE CONSTRAINT constraint_component_id IF NOT EXISTS FOR (n:Component) REQUIRE n.component_id IS UNIQUE;
            CREATE CONSTRAINT constraint_canvas_node_id IF NOT EXISTS FOR (n:CanvasNode) REQUIRE n.node_id IS UNIQUE; // Generic ID for other important nodes
            CREATE INDEX index_Î¼T_status IF NOT EXISTS FOR (n:MicroTask) ON (n.status);
            CREATE INDEX index_feature_status IF NOT EXISTS FOR (n:Feature) ON (n.status);
            CREATE INDEX index_node_type_label IF NOT EXISTS FOR (n:CanvasNode) ON (n.type_label); // For faster lookup by conceptual types
            CREATE INDEX index_pheromone_strength IF NOT EXISTS FOR (n:Feature) ON (n.priority_pheromone_strength_trailğŸ“ˆ);
            ```
    *   **Deliverables:** Detailed `Neo4jInstance_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas with verifications, metrics, and benchmark results. Core schema indices/constraints confirmed or created.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_MCP_VERIFY_003`. If benchmarks are slow or storage low, create `warnâ—` on `Neo4jInstance_ğŸ•¸ï¸N`.
    *   **Success Criteria (ğŸš¦):** All verifications pass and logged. Schema elements created/confirmed. Performance baseline recorded.

### 1.3. Infrastructure Setup: Core MCP Server Comprehensive Verification & Configuration Logging (Î¼T_SYS_INIT_MCP_VERIFY_003)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ›ï¸mcp_coordinator`
    *   **Task Description:** Comprehensively verify connectivity, retrieve version, and log KEY configuration parameters of ALL essential MCP servers (`MemoryBankğŸ”¥`, `Context7`, `SequentialThinking`, `PerplexityAsk`, and any custom project MCPs like one for Neo4j if built). Log this to individual `MCPInstance_ğŸ•¸ï¸N` nodes in ğŸ•¸ï¸Canvas, linked to `Project_ğŸ•¸ï¸N`.
    *   **Action (by `ğŸ›ï¸mcp_coordinator` through `use_mcp_tool`):**
        *   For EACH essential MCP server listed in Project Weaver's configuration:
            1.  Attempt `use_mcp_tool [MCP_Name] health_check` (or similar conventional endpoint).
            2.  Attempt `use_mcp_tool [MCP_Name] get_version_info`.
            3.  Attempt `use_mcp_tool [MCP_Name] get_active_config_summary` (this would be an ideal endpoint; if not available, skip or log 'config_not_retrievable'). Example data: MemoryBank's backend, Context7's Upstash link status, SeqThinking default model if any.
            4.  Instruct `ğŸ§ cognitive_navigator` to create/update an `MCPInstance_ğŸ•¸ï¸N` for this MCP: `MERGE (mcp:MCPInstance {name: $mcpName, project_id: $projectId}) SET mcp.url = $mcpUrl, mcp.health_status = $health, mcp.version = $version, mcp.config_summary = $configSummary, mcp.last_verified = datetime() WITH mcp MATCH (p:Project {project_id: $projectId}) MERGE (p)-[:USES_MCP_INSTANCE]->(mcp)`.
    *   **Deliverables:** Detailed status, version, and config summary (where available) for all core MCPs stored as `MCPInstance_ğŸ•¸ï¸N` nodes in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_CLOUD_VERIFY_004`. If any critical MCP reports `unreachable` or a problematic config, generate a strong `warnâ—` pheromone on its respective `MCPInstance_ğŸ•¸ï¸N` and also on the `Project_ğŸ•¸ï¸N` (e.g., `project_has_mcp_issue_warnâ—` relationship to the faulty `MCPInstance_ğŸ•¸ï¸N`).
    *   **Success Criteria (ğŸš¦):** All core MCPs respond to health check. Version and available config data logged to ğŸ•¸ï¸Canvas.

### 1.4. Infrastructure Setup: Cloud Provider Service, API Key Validation, & Billing Verification (Î¼T_SYS_INIT_CLOUD_VERIFY_004)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `â˜ï¸cloud_architect` (using provider CLI/SDKs via `execute_command` or provider-specific MCPs, if available).
    *   **Task Description:** For each configured LLM provider (Google Gemini, Anthropic Claude, OpenAI, etc.): verify API key validity by making a minimal, non-billable/low-cost call (e.g., list available models). Check current project billing status/alerts for that provider. Log API endpoint reachability, key validation status, and relevant quota information into `CloudProviderService_ğŸ•¸ï¸N` nodes in ğŸ•¸ï¸Canvas.
    *   **Action (by `â˜ï¸cloud_architect` for each LLM provider defined in Roo Code settings):**
        1.  Securely retrieve API key (e.g., from `${env:PROVIDER_API_KEY}`).
        2.  Perform a lightweight API call (e.g., `gcloud ai models list --region=us-central1` for Vertex, or equivalent for Anthropic/OpenAI using their client libraries in a script). Log `api_key_validation_status: 'VALID'/'INVALID'`, `service_endpoint_status: 'REACHABLE'/'UNREACHABLE'`.
        3.  If possible via API/CLI, query key quota information (e.g., `TokensPerMinute`, `RequestsPerDay`). If not, create a placeholder for manual update and a `guideâœ¨_manual_quota_check_needed` pheromone.
        4.  Manually or programmatically (if provider supports) check for any billing alerts or holds on the associated account. Log `billing_status: 'OK'/'ALERT_NEEDS_ATTENTION'`.
        5.  Instruct `ğŸ§ cognitive_navigator` to store this info in a `CloudProviderService_ğŸ•¸ï¸N` (e.g., `MERGE (cps:CloudProviderService {name: $providerName, project_id: $projectId}) SET cps.apiKeyValidated = $keyStatus, cps.endpointReachable = $endpointStatus, cps.quotaInfo = $quotaDetails, cps.billingStatus = $billingStatus, cps.last_verified = datetime() ...`).
    *   **Deliverables:** `CloudProviderService_ğŸ•¸ï¸N` nodes in ğŸ•¸ï¸Canvas for each configured LLM provider, detailing API key validity, service reachability, known quotas, and billing status.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_GIT_SETUP_005`. Generate strong `warnâ—` on `Project_ğŸ•¸ï¸N` and relevant `CloudProviderService_ğŸ•¸ï¸N` if any API key is invalid, service is unreachable, billing has issues, or critical quotas are nearly exhausted.
    *   **Success Criteria (ğŸš¦):** All configured LLM provider APIs validated for access. Key service health & billing info logged.

### 1.5. Version Control & Secure Project Workspace Setup (Î¼T_SYS_INIT_GIT_SETUP_005)
    *   **Assignee:** `ğŸŒŒWeaverCore` (using `execute_command`) & `ğŸ›¡ï¸security_auditor` (for advice and Canvas documentation of secret strategy)
    *   **Task Description:** Ensure a robust and secure Git repository setup: initialize if needed, implement a comprehensive `.gitignore` (from a `ğŸ•¸ï¸N_gitignore_template_advanced` chosen based on dominant languages in `initial_tech_profile_preference`), establish and document the project's branching strategy (e.g., GitFlow derivative) in ğŸ•¸ï¸Canvas. Document the chosen secrets management approach in ğŸ•¸ï¸Canvas (e.g., use of `.env` files sourced by shell, Doppler, HashiCorp Vault; actual setup of these tools is external but Weaver needs to *know* the strategy). Configure pre-commit hooks if specified in `initial_tech_profile_preference`.
    *   **Actions:**
        1.  `execute_command`: `git rev-parse --is-inside-work-tree` (to check if already a git repo). If not, `git init`.
        2.  `execute_command`: `mkdir -p src tests docs cicd scripts .roo .vscode .secrets_config_docs` (standard + a dir to store docs about secrets strategy if not using a tool).
        3.  `ğŸ§ cognitive_navigator`: Fetch `ğŸ•¸ï¸N_gitignore_template_advanced` (selected based on primary language(s) from `initial_tech_profile_preference`). Write its content to project root `.gitignore`.
        4.  `ğŸ›¡ï¸security_auditor`: Analyze `initial_tech_profile_preference` for common secret types (API keys, DB creds). Using `sequential_thinking` (if needed for complex cases), draft a recommended `SecretsManagementStrategy_ğŸ•¸ï¸N_doc` for this project (e.g., "Use .env file for local dev, load from shell ENV VARS. For CI/CD, use GitHub Actions Secrets. For production, use Cloud Provider's secret manager."). Instruct `ğŸ§ cognitive_navigator` to store this as a `ProjectDocumentation_ğŸ•¸ï¸N` linked to `Project_ğŸ•¸ï¸N`. Create `.env.example` file via `âš¡coder`.
        5.  `execute_command`: Draft a `BranchingStrategy.md` (e.g., based on GitFlow: `main`, `develop`, `feature/xxx`, `release/vy.y.z`, `hotfix/zzz`). Instruct `ğŸ§ cognitive_navigator` to store this as `BranchingStrategy_ğŸ•¸ï¸N_doc` linked to `Project_ğŸ•¸ï¸N`. `git checkout -b develop`.
        6.  `execute_command` (IF `initial_tech_profile_preference.precommit_hook_config_url_ğŸ•¸ï¸N_ref` exists AND `pre-commit` tool available): Download config, `pre-commit install`. Log `precommit_status: 'CONFIGURED'/'NOT_AVAILABLE'` on `Project_ğŸ•¸ï¸N`.
        7.  `execute_command`: `git add .gitignore README.md plan.md roo_modes_*.json umi_*.txt .env.example BranchingStrategy.md .secrets_config_docs/secrets_strategy.md`
        8.  `execute_command`: `git commit -m "feat(project_weaver): Established secure VCS workspace, branching strategy, .gitignore, secrets protocol, pre-commit hooks (if configured)"`
    *   **Deliverables:** Securely configured Git repository. Comprehensive `.gitignore`. Documented secrets management strategy (`SecretsManagement_ğŸ•¸ï¸N_doc`) and branching strategy (`BranchingStrategy_ğŸ•¸ï¸N_doc`) stored in ğŸ•¸ï¸Canvas. Pre-commit hooks active if configured.
    *   **Pheromone Update:** Boost `trailğŸ“ˆ` for `Î¼T_SYS_INIT_PROFILE_LOCK_006`. `guideâœ¨` on `Project_ğŸ•¸ï¸N` pointing to these strategy docs.
    *   **Success Criteria (ğŸš¦):** All Git setup actions successful. Strategy documents created in Canvas. `git status` clean post-commit.

### 1.6. Confirm, Lock, & Detail Active Operational & Tech Profiles into Phase Configuration (Î¼T_SYS_INIT_PROFILE_LOCK_006)
    *   **Assignee:** `ğŸŒŒWeaverCore` -> `ğŸ§©meta_strategist` (Primary Decision Maker) -> `ğŸ§ cognitive_navigator` (To Store Configuration)
    *   **Task Description:** This is a CRITICAL Î¼T. `ğŸ§©meta_strategist` analyzes the full project charter (`Project_ğŸ•¸ï¸N` from Î¼T_SYS_INIT_CHARTER_001), current infrastructure status (verified in Î¼Ts 1.2-1.5), and all available `ğŸ•¸ï¸N_op_profile_template`s / `ğŸ•¸ï¸N_tech_profile_template`s in ğŸ•¸ï¸Canvas. It then DEFINITIVELY SELECTS or CUSTOMIZES an Operational Profile and a Technology Stack Profile. ALL parameters of these chosen and potentially customized profiles (LLM choices, all cost thresholds ğŸ’° for different tool/Î¼T types, data tiering preferences for artifact types, Docker testing policies, research authorization logic, specific commands for linters/testers/builders from TechProfile, etc.) are explicitly SNAPSHOTTED into a new, versioned `CurrentPhaseConfig_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas. This node serves as the immutable configuration for all subsequent operations in the current major project phase (e.g., "Initial Development Phase").
    *   **Action:**
        1.  `ğŸ§©meta_strategist` requests `ğŸ§ cognitive_navigator` to list all available `ğŸ•¸ï¸N_op_profile_template`s and `ğŸ•¸ï¸N_tech_profile_template`s.
        2.  `ğŸ§©meta_strategist` uses `sequential_thinking` (providing `Project_ğŸ•¸ï¸N.charter_details`, `Project_ğŸ•¸ï¸N.initial_complexity_ğŸ²R`, `Project_ğŸ•¸ï¸N.budget_ğŸ¦_status`, and available template profile summaries as context) to:
            *   Select the most suitable base OpProfile and TechProfile templates.
            *   Identify any parameters within these templates that need tuning/customization for *this specific project* and *this initial phase*. For example, it might override a default LLM if the project budget is tight, or set a very specific linter command from a TechProfile template if the project language demands it.
        3.  `ğŸ§©meta_strategist` compiles a complete, resolved set of ALL operational and technical parameters.
        4.  `ğŸ§©meta_strategist` instructs `ğŸ§ cognitive_navigator` to:
            ```cypher
            // Create the CurrentPhaseConfig node
            CREATE (phase_config:CurrentPhaseConfig {
                phase_config_id: "CFG_" + $projectId + "_INIT_PHASE_001", // Ensure unique ID
                project_id: $projectId,
                phase_name: "SYS_INIT_ECO_001_OPERATIONAL_CONFIG",
                timestamp_created: datetime(),
                op_profile_source_name: $chosenOpProfileTemplateName, // Name of the template it was based on
                tech_profile_source_name: $chosenTechProfileTemplateName,
                // --- DETAILED SNAPSHOTTED PARAMETERS ---
                // LLM Configurations
                llm_profile_id_coding_default: $resolvedParams.llm_coding_default,
                llm_profile_id_coding_robust_for_high_dice_r: $resolvedParams.llm_coding_robust,
                llm_profile_id_spec_writing: $resolvedParams.llm_spec,
                llm_profile_id_architecture: $resolvedParams.llm_arch,
                llm_profile_id_debugging_reasoning: $resolvedParams.llm_debug_reasoning,
                llm_profile_id_documentation: $resolvedParams.llm_docs,
                llm_profile_id_sequential_thinking_default: $resolvedParams.llm_seq_think,
                // Cost Thresholds ğŸ’°
                cost_threshold_Î¼T_coding_low_dice_r_ğŸ’°: $resolvedParams.cost_Î¼T_code_low_ğŸ²R,
                cost_threshold_Î¼T_coding_high_dice_r_ğŸ’°: $resolvedParams.cost_Î¼T_code_high_ğŸ²R,
                cost_threshold_Î¼T_research_ğŸ’¡ask_ğŸ’°: $resolvedParams.cost_Î¼T_research,
                cost_threshold_Î¼T_deep_canvas_query_ğŸ•¸ï¸P_ğŸ’°: $resolvedParams.cost_Î¼T_deep_canvas,
                // Data Storage Policies
                data_strategy_default_Î¼T_artifact_tier: $resolvedParams.storage_Î¼T_artifacts, // e.g., "MemoryBank_1hr_ttl"
                data_strategy_strategic_outcome_tier: "Neo4j_Cognitive_Canvas", // Usually fixed
                data_strategy_cache_retrieval_order: $resolvedParams.cache_retrieval_order, // e.g., ["MemoryBank", "SQLite_KB", "Neo4j_Shallow"]
                // Tool Usage Policies
                research_policy_perplexity_budget_per_Î¼T_ğŸ’°: $resolvedParams.research_perplexity_budget,
                research_trigger_conditions_pheromones: $resolvedParams.research_trigger_pheromones, // e.g., ["warnâ—_no_internal_solution_strong", "guideâœ¨_external_research_needed"]
                // Docker & Testing Policies (from chosen TechProfile, but confirmed here)
                tech_profile_requires_docker_for_tests: $chosenTechProfile.requires_docker_for_tests,
                tech_profile_docker_compose_file: $chosenTechProfile.docker_compose_file_default,
                tech_profile_unit_test_command: $chosenTechProfile.unit_test_command,
                tech_profile_integration_test_command: $chosenTechProfile.integration_test_command,
                tech_profile_linter_command: $chosenTechProfile.linter_command,
                tech_profile_sast_tool_mcp_name: $chosenTechProfile.sast_tool_mcp,
                // Other essential parameters...
                spec_detail_level_default: $resolvedParams.spec_detail,
                architecture_phase_trigger_threshold_ğŸ²R: $resolvedParams.arch_phase_trigger_ğŸ²R,
                max_Î¼T_loc_target: 50
            })
            WITH phase_config
            MATCH (p:Project {project_id: $projectId})
            MERGE (p)-[r_cfg:ACTIVE_PHASE_CONFIGURATION]->(phase_config) SET r_cfg.since = datetime()
            RETURN phase_config.phase_config_id AS lockedConfigId;
            ```
    *   **Deliverables:** A comprehensive `CurrentPhaseConfig_ğŸ•¸ï¸N` exists in ğŸ•¸ï¸Canvas, its ID known. This node serves as the immutable source of operational truth for `ğŸŒŒWeaverCore` and all other modes for the entire current phase.
    *   **Pheromone Update:** Extremely strong `trailğŸ“ˆ` from `Project_ğŸ•¸ï¸N` to "Section 2: Feature Development - [FIRST_FEATURE_NAME]" master pheromone. This signals "SYSTEM READY FOR DEVELOPMENT". Place a `guideâœ¨` pheromone relationship from `Project_ğŸ•¸ï¸N` to the created `CurrentPhaseConfig_ğŸ•¸ï¸N` for easy lookup by `ğŸŒŒWeaverCore`.
    *   **Success Criteria (ğŸš¦):** `CurrentPhaseConfig_ğŸ•¸ï¸N` fully populated with all necessary explicit operational parameters in ğŸ•¸ï¸Canvas. Its ID is confirmed and returned. `ğŸŒŒWeaverCore` acknowledges it can now retrieve this for all subsequent phase operations.

---

## ğŸ’» Section 2: Feature Development - [FEATURE_NAME_1] (Phase: `FEAT_DEV_001_[FeatureSlug]`)

**Parent Project ID (ğŸ•¸ï¸N_project_id):** `[ID_FROM_SECTION_1]`
**>>> Active Configuration ID (CurrentPhaseConfig_ğŸ•¸ï¸N_id):** `[ID_FROM_Î¼T_SYS_INIT_PROFILE_LOCK_006 (e.g., CFG_INIT_001_PROJECTID)]` **<<< CRITICAL INPUT for `ğŸŒŒWeaverCore` to orchestrate ALL Î¼Tasks in this section.**
**Pheromone Focus (trailğŸ“ˆ for this Feature Phase):** `develop_feature_[FeatureSlug]` (Initial strength set by `ğŸ¤”reflection_engine/scribe` when `ğŸŒŒWeaverCore` starts this feature)
**Overall Feature Goal:** `[High-level description of the feature, e.g., "Implement robust user authentication with email/password, including registration, login, and password reset."]`
**Feature ID (ğŸ•¸ï¸N_feature_id):** `[AUTO_GEN_FeatureSlug_001]` (Created in ğŸ•¸ï¸Canvas by `ğŸŒŒWeaverCore` upon parsing this section, linked to `Project_ğŸ•¸ï¸N` and the Active `CurrentPhaseConfig_ğŸ•¸ï¸N_id`)
**Estimated Story Points / Initial Complexity (ğŸ²R_feature_complexity):** `[e.g., 8]` (Stored on `Feature_ğŸ•¸ï¸N` by `ğŸŒŒWeaverCore` perhaps after a quick `sequential_thinking` assessment of the goal).

*(For each Feature, create a new Section like this. `ğŸŒŒWeaverCore` first retrieves the Active `CurrentPhaseConfig_ğŸ•¸ï¸N` using the ID above. Then, for EVERY Î¼Task in this section, `ğŸŒŒWeaverCore` will use the parameters from that config node to: a) decide which tools to use (LLMs, MCPs, Docker), b) determine cost/budget limits, c) specify data storage tiers, d) define testing rigor, etc., and pass these specifics as part of the directive to the assigned worker mode.)*

### 2.1. Deep Specification Elaboration & Validation Loop (Sub-Phase: `FEAT_SPEC_[FeatureSlug]_001`)

#### 2.1.1. Generate Initial Detailed Specifications (Î¼T_FEAT_[FeatureSlug]_SPEC_DRAFT_001.1)
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `feature_goal`, `Feature_ğŸ•¸ï¸N_id`, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, and `Î¼T_resolved_tooling_strategy` (specifying e.g., `llm_profile_id: CurrentPhaseConfig.llm_for_spec_writing`, `data_output_tier_preference: Neo4j_Cognitive_Canvas_for_spec_ğŸ•¸ï¸N`, `ambiguity_resolution_tool_policy: CurrentPhaseConfig.OpProfile.spec_ambiguity_resolver`).
    *   **Assignee:** `ğŸ“spec_writer`
    *   **Task Description:** Generate detailed BDD scenarios, TDD test anchors, user stories, NFRs, data model sketches for `Feature_ğŸ•¸ï¸N_id`. Adhere to `CurrentPhaseConfig.OpProfile.spec_detail_level`. Query `ğŸ§ cognitive_navigator` (per `CurrentPhaseConfig.DataStrategy.spec_context_retrieval_policy`) for related `ğŸ•¸ï¸P_existing_specs` and any `warnâ—`/`guideâœ¨` pheromones. If ambiguity (ğŸš©) is high, use tool specified in `Î¼T_tooling_strategy.ambiguity_resolution_tool` (e.g., `mcpğŸ“SequentialThinking`), or flag ğŸš© for `ğŸŒŒWeaverCore`'s Ambiguity Resolution Protocol.
    *   **Deliverables:**
        *   Draft `feature_spec_detail_ğŸ•¸ï¸N` stored in `ğŸ•¸ï¸Cognitive_Canvas` (via `ğŸ§ cognitive_navigator`, as per `Î¼T_tooling_strategy.data_output_tier_preference`).
        *   File `docs/specs/[feature_slug]_spec_draft_v1.md` (storage handled by `ğŸ“spec_writer` based on `CurrentPhaseConfig.DataStrategy.physical_artifact_storage_policy`).
        *   Ambiguity flags (ğŸš©_property on `feature_spec_detail_ğŸ•¸ï¸N`) set if unresolved issues.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** `trailğŸ“ˆ` on `Î¼T_FEAT_[FeatureSlug]_SPEC_REVIEW_001.2`.
    *   **Success Criteria (ğŸš¦):** Draft spec fully populated. Stored in specified tiers. Ambiguities handled or explicitly flagged ğŸš©.

#### 2.1.2. Automated Spec Review & Consistency Check (Î¼T_FEAT_[FeatureSlug]_SPEC_REVIEW_001.2)
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `feature_spec_detail_ğŸ•¸ï¸N_id` (draft), `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, and `Î¼T_resolved_tooling_strategy` (specifying e.g., `llm_profile_id: CurrentPhaseConfig.OpProfile.spec_review_llm`, `max_review_cost_ğŸ’°: CurrentPhaseConfig.OpProfile.spec_review_budget_ğŸ’°`).
    *   **Assignee:** `ğŸŒŒWeaverCore` -> (Sub-mode like `ğŸ§spec_analyzer_bot` or direct `mcpğŸ“SequentialThinking` call, per `Î¼T_resolved_tooling_strategy`).
    *   **Task Description:** Review draft spec for internal consistency, clarity, completeness against `Feature_ğŸ•¸ï¸N.goal`, and alignment with NFRs from `CurrentPhaseConfig_ğŸ•¸ï¸N.ProjectDefaults.nfr_ğŸ•¸ï¸N_ids_list`. Query `ğŸ§ cognitive_navigator` (per `DataStrategy`) for conflicts with existing `feature_spec_ğŸ•¸ï¸N`s or `architecture_design_ğŸ•¸ï¸N`s.
    *   **Deliverables:** `SpecReviewReport_ğŸ•¸ï¸N` linked to `feature_spec_detail_ğŸ•¸ï¸N` (stored in ğŸ•¸ï¸Canvas per `Î¼T_resolved_tooling_strategy.data_output_tier_preference`). Contains structured list of issues/suggestions or validation status.
    *   **Pheromone Update:** If issues found, `warnâ—` on draft spec ğŸ•¸ï¸N & strong `trailğŸ“ˆ` back to `ğŸ“spec_writer` for `Î¼T_FEAT_..._SPEC_REVISE_X`. If validated, set `feature_spec_detail_ğŸ•¸ï¸N.validation_status = 'VALIDATED'` and strong `trailğŸ“ˆ` to next phase (e.g., architecture or first coding Î¼T for the feature).
    *   **Success Criteria (ğŸš¦):** Review report generated and stored. Spec `validation_status` updated.

*(Repeat SPEC_DRAFT 2.1.1 and SPEC_REVIEW 2.1.2 with new version numbers if revisions are needed until `validation_status` is 'VALIDATED')*

### 2.2. Detailed Architectural Breakdown & Risk Analysis (Sub-Phase: `FEAT_ARCH_[FeatureSlug]_002`) - *Conditional: `ğŸŒŒWeaverCore` triggers this IF (`Feature_ğŸ•¸ï¸N.initial_complexity_ğŸ²R` > `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.architecture_phase_trigger_threshold_ğŸ²R`) OR (`feature_spec_detail_ğŸ•¸ï¸N.implies_new_services == true`)*

#### 2.2.1. Generate Architectural Options & Trade-offs (Î¼T_FEAT_[FeatureSlug]_ARCH_OPTIONS_002.1)
    *   **Directive from `ğŸŒŒWeaverCore` includes:** Validated `feature_spec_detail_ğŸ•¸ï¸N_id`, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, `Î¼T_resolved_tooling_strategy` (LLM choice, data tier for report).
    *   **Assignee:** `ğŸ—ï¸architect`
    *   **Task Description:** Propose 1-3 high-level architectural approaches for `Feature_ğŸ•¸ï¸N_id`. Query `ğŸ§ cognitive_navigator` (per `DataStrategy`) for existing `ğŸ•¸ï¸P_arch_patterns` relevant to `CurrentPhaseConfig_ğŸ•¸ï¸N.TechProfile`, existing `ğŸ²R_scores` of components to be integrated with, and `guideâœ¨`/`warnâ—` pheromones on architectural patterns or similar past features. Document trade-offs (costğŸ’°, performance, complexityğŸ²R, securityğŸ²R) for each option based on OpProfile priorities.
    *   **Deliverables:** `ArchOptionsReport_ğŸ•¸ï¸N` (containing multiple `ArchOptionSketch_ğŸ•¸ï¸N` details) stored in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `Î¼T_FEAT_[FeatureSlug]_ARCH_SELECT_002.2`.
    *   **Success Criteria (ğŸš¦):** Report with distinct, well-reasoned options and comparative trade-offs generated.

#### 2.2.2. Select & Detail Chosen Architecture (Î¼T_FEAT_[FeatureSlug]_ARCH_SELECT_002.2)
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `ArchOptionsReport_ğŸ•¸ï¸N_id`, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, `Feature_ğŸ²R_complexity`.
    *   **Assignee:** `ğŸ§©meta_strategist` (Decision maker using `mcpğŸ“SequentialThinking` as specified in `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.architecture_selection_tool`) with `ğŸ—ï¸architect` providing detailed design of selected option.
    *   **Task Description:** `ğŸ§©meta_strategist` analyzes options from report against OpProfile strategic goals (e.g., long-term scalability vs. short-term cost). Selects optimal architecture. `ğŸ—ï¸architect` then fully details chosen architecture: define all new/modified `component_ğŸ•¸ï¸N`s, `Interface_ğŸ•¸ï¸N`s (e.g., OpenAPI specs), `DataModel_ğŸ•¸ï¸N`s, and `ğŸ•¸ï¸R_interactions`. Document as an Architectural Decision Record (ADR_ğŸ•¸ï¸N). If chosen architecture implies high cost (per `OpProfile.high_cost_design_threshold_ğŸ’°`), flag for `docsğŸ’°` justification by `ğŸ—ï¸architect`.
    *   **Deliverables:** Final `architecture_design_ğŸ•¸ï¸N` (with all detailed `component_ğŸ•¸ï¸N`s, `interface_ğŸ•¸ï¸N`s, etc.) linked to `feature_spec_detail_ğŸ•¸ï¸N`. `ADR_ğŸ•¸ï¸N` also created and linked. All stored in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** Strong `guideâœ¨` from `architecture_design_ğŸ•¸ï¸N` to individual `component_ğŸ•¸ï¸N`s, outlining implementation path for `âš¡coder`. Strong `trailğŸ“ˆ` to the first `_CODEIMP_` Î¼T for this feature. If design implies risky integrations, relevant `warnâ—` pheromones may be created/strengthened by `ğŸ¤”reflection_engine/scribe` upon logging of this design.
    *   **Success Criteria (ğŸš¦):** Chosen architecture fully detailed, ADR documented, all relevant entities represented in ğŸ•¸ï¸Canvas. `docsğŸ’°` justification logged if needed.

### 2.3. Iterative Code & Test Implementation Loop (Sub-Phase: `FEAT_CODE_TEST_[FeatureSlug]_003`)
*(`ğŸŒŒWeaverCore` identifies each `component_ğŸ•¸ï¸N` or logical code unit from `architecture_design_ğŸ•¸ï¸N` (or `feature_spec_detail_ğŸ•¸ï¸N` if no arch phase). For each unit, it creates a sequence of Î¼Tasks below, providing the explicit `Î¼T_resolved_tooling_and_data_strategy` based on `CurrentPhaseConfig_ğŸ•¸ï¸N` and current context like unit ğŸ²R or pheromones guideâœ¨/warnâ—.)*

#### **Micro-Loop for Component/Unit: `[ComponentNameOrUnitSlug]`** (Example: `UserAuthService` or `PasswordHasherUtil`)

##### 2.3.[X].1. Define Detailed Test Cases (TDD - Tests First) (Î¼T_FEAT_[FeatureSlug]_TESTDEF_[UnitSlug]_001)
    *   **Directive from `ğŸŒŒWeaverCore`:** `component_ğŸ•¸ï¸N_id` (or unit description), `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, and `Î¼T_resolved_tooling_strategy` (LLM for test gen, test framework from `TechProfile.unit_test_framework`, target file `tests/[path/to/test_unit.ext]`, data output to ğŸ•¸ï¸Canvas for `TestCase_ğŸ•¸ï¸N`).
    *   **Assignee:** `ğŸ“spec_writer` or `âš¡coder` (per `OpProfile.test_definition_assignee_policy`).
    *   **Task Description:** Based on `component_ğŸ•¸ï¸N`'s defined responsibilities/interfaces (from `architecture_design_ğŸ•¸ï¸N` or `feature_spec_detail_ğŸ•¸ï¸N`), write detailed, executable (but initially failing) test cases in the specified test file. Cover unit-level positive, negative, boundary/edge cases identified in TDD anchors from spec or inferred for robustness. Focus on testable contracts.
    *   **Deliverables:** Test code file `tests/[path/to/test_unit.ext]` created/updated. `TestCase_ğŸ•¸ï¸N` definitions for each test (or an overarching `TestSuite_ğŸ•¸ï¸N` for the unit) created in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`, linked to the conceptual `CodeModule_ğŸ•¸ï¸N` for this unit. Set `CodeModule_ğŸ•¸ï¸N.tdd_status_ğŸš¦ = 'TESTS_DEFINED'`.
    *   **Pheromone Update:** Strong `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_CODEIMP_[UnitSlug]_002`. Strong `guideâœ¨` pheromone from these new `TestCase_ğŸ•¸ï¸N`s pointing to the target `CodeModule_ğŸ•¸ï¸N`.
    *   **Success Criteria (ğŸš¦):** Test file exists with runnable (failing) test stubs/cases covering specified requirements. Corresponding `TestCase_ğŸ•¸ï¸N` entities logged in ğŸ•¸ï¸Canvas and linked.

##### 2.3.[X].2. Implement Code Unit (Î¼T_FEAT_[FeatureSlug]_CODEIMP_[UnitSlug]_002)
    *   **Directive from `ğŸŒŒWeaverCore`:** `component_ğŸ•¸ï¸N_id` or unit description, associated `TestCase_ğŸ•¸ï¸N_ids_to_pass`, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`, and `Î¼T_resolved_tooling_strategy` (LLM profile for coding (e.g., `claude-3.5-sonnet_careful_coder_profile`), target source file `src/[path/to/code_unit.ext]`, any authorized `ğŸ’¡ask_ğŸ’°_budget` for this specific implementation if `warnâ—_complex_implementation` exists).
    *   **Assignee:** `âš¡coder`.
    *   **Task Description:** Implement the source code for `[ComponentNameOrUnitSlug]` in the specified file, ensuring it fulfills its requirements and aims to make ALL associated, previously defined `TestCase_ğŸ•¸ï¸N`s pass. Adhere to coding standards in `CurrentPhaseConfig_ğŸ•¸ï¸N.TechProfile.coding_standards_ğŸ•¸ï¸N_ref`. Utilize libraries specified in TechProfile unless justification for new ones. Consider any `guideâœ¨`/`warnâ—` pheromones related to this unit.
    *   **Research Trigger (by `âš¡coder` via `ğŸŒŒWeaverCore` if strategy permits ğŸ’¡ask):** If internal lookups (ğŸ”¥,ğŸ§±,ğŸ•¸ï¸ specific pattern query per strategy) fail and `ğŸ’¡ask_ğŸ’°_budget` available, `âš¡coder` requests `ğŸŒŒWeaverCore` to task `ğŸ”¬github_researcher`.
    *   **Deliverables:** Source code file `src/[path/to/code_unit.ext]` created/updated. `CodeModule_ğŸ•¸ï¸N` (or `Function_ğŸ•¸ï¸N`, `Class_ğŸ•¸ï¸N`) details (like dependencies discovered, LOC) updated in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`.
    *   **Pheromone Update:** Strong `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_QUALCHK_[UnitSlug]_003`.
    *   **Success Criteria (ğŸš¦):** Source code implemented as specified. (Actual operational success is gated by subsequent ğŸš¦Quality Gate and Test Execution).

##### 2.3.[X].3. Quality Gate Check for Code Unit (Î¼T_FEAT_[FeatureSlug]_QUALCHK_[UnitSlug]_003) - MANDATORY
    *   **Directive from `ğŸŒŒWeaverCore`:** Path to code file(s) for `[UnitSlug]`, corresponding `TestCase_ğŸ•¸ï¸N_ids` from Canvas, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸš¦quality_gatekeeper`.
    *   **Task Description:** Perform full Quality Gate:
        1.  Static Analysis: Run linters/static analyzers specified in `CurrentPhaseConfig_ğŸ•¸ï¸N.TechProfile.linter_command` / `sast_tool_mcp_name`.
        2.  Compliance & Standards: Check against rules in `CurrentPhaseConfig_ğŸ•¸ï¸N.ProjectDefaults.coding_standards_ğŸ•¸ï¸N_ref` via `ğŸ§ cognitive_navigator`.
        3.  **TDD Adherence & Test Coverage Assessment:** Query `ğŸ§ cognitive_navigator` to verify that the implemented code in `[UnitSlug]` has thorough, non-stub tests defined in the linked `TestCase_ğŸ•¸ï¸N`s. (Optionally, if TechProfile includes a coverage tool and OpProfile allows: run coverage tool, check if it meets `OpProfile.min_unit_test_coverage_percent`).
    *   **Deliverables:** Status: PASS/FAIL (with detailed reasons: e.g., `FAIL_LINTING`, `FAIL_TDD_INCOMPLETE_TESTS`, `FAIL_LOW_COVERAGE`). Detailed `quality_report_ğŸ•¸ï¸N` logged to ğŸ•¸ï¸Canvas, linked to the `CodeModule_ğŸ•¸ï¸N`.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** IF FAIL, strong `warnâ—` on the preceding `_CODEIMP_` `Î¼T_ğŸ•¸ï¸N` and relevant `CodeModule_ğŸ•¸ï¸N`. `trailğŸ“ˆ` is routed back to `âš¡coder` for rework. IF PASS, update `CodeModule_ğŸ•¸ï¸N.tdd_status_ğŸš¦ = 'CODE_QUALITY_PASSED'` and `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_TESTEXEC_[UnitSlug]_004`.
    *   **Success Criteria (ğŸš¦):** Overall status is PASS. All checks meet criteria defined in `CurrentPhaseConfig_ğŸ•¸ï¸N`. TDD check confirms sufficient tests map to implemented code.

##### 2.3.[X].4. Execute Unit Tests (Î¼T_FEAT_[FeatureSlug]_TESTEXEC_[UnitSlug]_004)
    *   **Directive from `ğŸŒŒWeaverCore`:** Test file path(s) for `[UnitSlug]`, source code path. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`. The `Î¼T_resolved_tooling_strategy` specifies Docker usage (e.g., "ğŸ³â†‘ `docker-compose.test.yml service_X` -> ğŸ³â†’ğŸƒ `TechProfile.unit_test_command_in_container` -> ğŸ³â†“") OR direct execution (`execute_command [TechProfile.unit_test_command_local]`).
    *   **Assignee:** Appropriate Tester mode (`ğŸ™ï¸chicago_tester` or `ğŸ‡¬ğŸ‡§london_tester` based on `TechProfile.default_unit_test_style` or Î¼T specific directive).
    *   **Task Description:** Execute all unit tests for `[ComponentNameOrUnitSlug]`. If strategy requires Docker, `ğŸŒŒWeaverCore` first instructs `ğŸ³docker_engineer` to set up the environment, then this tester runs tests (potentially via `ğŸ³docker_engineer` exec), then `ğŸŒŒWeaverCore` instructs teardown.
    *   **Deliverables:** `TestRun_ğŸ•¸ï¸N` (with PASS/FAIL status, detailed results, code coverage metrics if tool provides) logged to ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`, linked to the `TestSuite_ğŸ•¸ï¸N` and `CodeModule_ğŸ•¸ï¸N`.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** IF FAIL, strong `warnâ—` on `CodeModule_ğŸ•¸ï¸N` and relevant `TestCase_ğŸ•¸ï¸N`s. `trailğŸ“ˆ` routed to `ğŸ”debugger`. IF PASS, `guideâœ¨` pheromone of stability/correctness on `CodeModule_ğŸ•¸ï¸N`. Increment `trailğŸ“ˆ` for the next logical code unit/component in the feature, or to feature integration if this unit is the last one.
    *   **Success Criteria (ğŸš¦):** All unit tests for `[UnitSlug]` PASS. Code coverage meets or exceeds threshold in `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.min_unit_test_coverage_percent`. `TestRun_ğŸ•¸ï¸N` successfully logged.

##### 2.3.[X].5. Debug Unit (If Unit Tests Fail) (Î¼T_FEAT_[FeatureSlug]_DEBUG_[UnitSlug]_005) - *Conditional on FAIL status from previous Î¼T*
    *   **Directive from `ğŸŒŒWeaverCore`:** Failed `TestRun_ğŸ•¸ï¸N_id`, `CodeModule_ğŸ•¸ï¸N_id` with source code, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`. `Î¼T_resolved_tooling_strategy` specifies tiered knowledge lookup priority for debugging context (e.g., "1. `warnâ—`pheromones from ğŸ•¸ï¸Canvas for this code. 2. Recent errors from ğŸ”¥MemoryBank for similar sigs. 3. `mcpğŸ“SequentialThinking` with LLM `OpProfile.llm_for_debugging_reasoning`").
    *   **Assignee:** `ğŸ”debugger`.
    *   **Task Description:** Diagnose failed unit tests for `[UnitSlug]`. Retrieve context from ğŸ”¥MemoryBank (`ğŸ“šknowledge_base_operator`), ğŸ§±SQLite_KB (`ğŸ“šknowledge_base_operator`), and ğŸ•¸ï¸Cognitive_Canvas (`ğŸ§ cognitive_navigator`) as per Î¼T strategy. Use `mcpğŸ“SequentialThinking` if allowed by strategy for complex root cause analysis. Propose specific code change.
    *   **Deliverables:** `DebugReport_ğŸ•¸ï¸N` (root cause analysis, confidence ğŸ²R_in_fix) and `ProposedFix_ğŸ•¸ï¸N_diff` (a code diff) stored in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** `warnâ—` on original cause is strengthened. If `ProposedFix_ğŸ•¸ï¸N_diff` is generated, a `guideâœ¨` towards applying this fix. `trailğŸ“ˆ` to a new rework `Î¼T_FEAT_[FeatureSlug]_CODEIMP_[UnitSlug]_002.rework1`.
    *   **Success Criteria (ğŸš¦):** Root cause identified with supporting evidence. Actionable, minimal fix proposed as a diff.

*(End of Micro-Loop for Component/Unit. `ğŸŒŒWeaverCore` repeats 2.3.[X].1 through 2.T3.[X].5 for ALL components/units defined in the feature's architecture or spec. If a debug loop occurs, the sequence for that unit re-enters at CODEIMP with the proposed fix.)*

### 2.4. Feature Integration, System & End-to-End (E2E) Testing Loop (Sub-Phase: `FEAT_INTEGRATE_TEST_[FeatureSlug]_004`)
*(`ğŸŒŒWeaverCore` orchestrates this sub-phase once ALL individual units/components for the feature have PASS statuses from their respective unit test execution (Î¼T 2.3.[X].4) and quality gates (Î¼T 2.3.[X].3).)*

#### 2.4.1. Define Feature Integration Test Plan (Î¼T_FEAT_[FeatureSlug]_INTG_PLAN_001)
    *   **Directive from `ğŸŒŒWeaverCore`:** All implemented and unit-tested `CodeModule_ğŸ•¸ï¸N_ids` for `Feature_ğŸ•¸ï¸N_id`, `architecture_design_ğŸ•¸ï¸N_id` (if exists), `feature_spec_detail_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ—ï¸architect` or senior `ğŸ§ªtester-definer` (per `OpProfile.integration_test_planning_assignee_policy`).
    *   **Task Description:** Define integration test scenarios. Focus on interactions BETWEEN this feature's components AND interactions of this feature with existing key project components/services (identified from `ğŸ§ cognitive_navigator` query of `ğŸ•¸ï¸P_project_dependency_graph` relevant to `CurrentPhaseConfig_ğŸ•¸ï¸N.TechProfile`). Prioritize tests for high `ğŸ²R_interaction_points` (e.g., external API calls, shared database tables, complex data transformations between components).
    *   **Deliverables:** `IntegrationTestPlan_ğŸ•¸ï¸N` (with scenarios, setup, expected outcomes) stored in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`, linked to `Feature_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_INTG_IMPL_002`. `guideâœ¨` pheromones on component interactions that require specific testing.
    *   **Success Criteria (ğŸš¦):** Comprehensive and prioritized integration test plan defined and stored in ğŸ•¸ï¸Canvas.

#### 2.4.2. Implement Integration Tests (Î¼T_FEAT_[FeatureSlug]_INTG_IMPL_002)
    *   **Directive from `ğŸŒŒWeaverCore`:** `IntegrationTestPlan_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `TechProfile.integration_test_framework` and `OpProfile.llm_for_test_coding`).
    *   **Assignee:** `âš¡coder` or `ğŸ§ªtester-implementer`.
    *   **Task Description:** Implement the integration tests as code according to `IntegrationTestPlan_ğŸ•¸ï¸N`. Test environment setup (e.g., mock external services, seed test data) instructions should be part of plan, potentially using `CurrentPhaseConfig_ğŸ•¸ï¸N.TechProfile.test_data_seeding_script_path` or Docker services.
    *   **Deliverables:** Integration test suite code (e.g., `tests/integration/[feature_slug]_integration_tests.ext`). `IntegrationTestSuite_ğŸ•¸ï¸N` entity in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`, linked to plan and feature.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_INTG_EXEC_003`.
    *   **Success Criteria (ğŸš¦):** All planned integration tests implemented as runnable code.

#### 2.4.3. Execute Integration Tests (Î¼T_FEAT_[FeatureSlug]_INTG_EXEC_003)
    *   **Directive from `ğŸŒŒWeaverCore`:** `IntegrationTestSuite_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`. The `Î¼T_resolved_tooling_strategy` specifies execution environment: may involve Docker (`ğŸ³â†‘ â†’ ğŸ³â†’ğŸƒ â†’ ğŸ³â†“` orchestrated via `ğŸ³docker_engineer` for services defined in `TechProfile.docker_compose_integration_testing_file`) or direct (`execute_command [TechProfile.integration_test_command]`).
    *   **Assignee:** Specialized `ğŸ§ªintegration_tester` (or general Tester if appropriate per OpProfile).
    *   **Task Description:** Execute all implemented integration tests for the feature. Capture results and logs.
    *   **Deliverables:** `IntegrationTestRun_ğŸ•¸ï¸N` (PASS/FAIL, detailed results, coverage if tool supports for integration level) stored in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** IF FAIL, strong `warnâ—` on `Feature_ğŸ•¸ï¸N` and specifically on involved `component_ğŸ•¸ï¸N`s with high failure rates in this run. `trailğŸ“ˆ` routed to `ğŸ”debugger` for integration issues. IF PASS, strong `guideâœ¨` of stability on `Feature_ğŸ•¸ï¸N`.
    *   **Success Criteria (ğŸš¦):** All integration tests PASS. Detailed results logged.

#### 2.4.4. Define End-to-End (E2E) / User Acceptance Test (UAT) Scenarios (Î¼T_FEAT_[FeatureSlug]_UAT_DEF_004)
    *   **Directive from `ğŸŒŒWeaverCore`:** Original `feature_spec_detail_ğŸ•¸ï¸N_id` (especially user stories and BDD scenarios), `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ“spec_writer` or dedicated `ğŸ§ªuat_designer`.
    *   **Task Description:** Based on user stories and BDD from the feature spec, define high-level E2E test scenarios that mimic real user workflows for this feature. These should validate the feature's goal from an end-user perspective. Consider critical positive and negative paths. Specify test data requirements for UAT.
    *   **Deliverables:** `UAT_Scenario_Set_ğŸ•¸ï¸N` (listing scenarios, steps, expected results, test data needs) stored in ğŸ•¸ï¸Canvas, linked to `Feature_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_UAT_IMPL_005` (if automation planned) or directly to `_UAT_EXEC_` (if manual/semi-automated).
    *   **Success Criteria (ğŸš¦):** Comprehensive UAT scenarios covering feature's user-facing goals are defined and stored.

#### 2.4.5. Implement E2E / UAT Automation (Optional - If `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.e2e_test_automation_policy == 'AUTOMATE_ALL'` or `AUTOMATE_CRITICAL`) (Î¼T_FEAT_[FeatureSlug]_UAT_IMPL_005)
    *   **Directive from `ğŸŒŒWeaverCore`:** `UAT_Scenario_Set_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `TechProfile.e2e_automation_framework` like Selenium/Playwright/Cypress, and OpProfile LLM for coding these tests).
    *   **Assignee:** `âš¡coder` with E2E tool expertise or dedicated `ğŸ§ªe2e_automation_engineer`.
    *   **Task Description:** Implement automated test scripts for the defined UAT scenarios using the framework specified in TechProfile.
    *   **Deliverables:** E2E automated test scripts (e.g., `tests/e2e/[feature_slug]_e2e_tests.ext`). `E2E_TestSuite_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas linked to `UAT_Scenario_Set_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `_UAT_EXEC_`.
    *   **Success Criteria (ğŸš¦):** Automated E2E tests implemented and runnable for defined UAT scenarios.

#### 2.4.6. Execute E2E / UAT (Î¼T_FEAT_[FeatureSlug]_UAT_EXEC_006)
    *   **Directive from `ğŸŒŒWeaverCore`:** `UAT_Scenario_Set_ğŸ•¸ï¸N_id` (for manual/semi-auto) OR `E2E_TestSuite_ğŸ•¸ï¸N_id` (for automated). `CurrentPhaseConfig_ğŸ•¸ï¸N_id`. The `Î¼T_resolved_tooling_strategy` specifies if tests run against a staging environment (requiring `ğŸ³docker_engineer` or `â˜ï¸cloud_architect` for setup via directive if env not persistent) using automation tools from TechProfile.
    *   **Assignee:** `ğŸ§ªe2e_tester`.
    *   **Task Description:** Execute the E2E user acceptance tests. If GUI based, uses TechProfile browser automation tools (`execute_command [TechProfile.e2e_run_command]`).
    *   **Deliverables:** `UAT_Run_ğŸ•¸ï¸N` or `E2E_TestRun_ğŸ•¸ï¸N` (PASS/FAIL for each scenario) stored in ğŸ•¸ï¸Canvas via `ğŸ§ cognitive_navigator`.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** IF FAIL, strong `warnâ—` on `Feature_ğŸ•¸ï¸N`. `trailğŸ“ˆ` to `ğŸ”debugger` for E2E issues. IF ALL PASS, `status_pheromone` on `Feature_ğŸ•¸ï¸N` becomes `TESTING_COMPLETE_ jakoÅ›ci_PASS`. Strong `trailğŸ“ˆ` to `Î¼T_FEAT_[FeatureSlug]_DOC_DRAFT_001` or "Section 3: Release Preparation" if documentation is already complete or handled separately.
    *   **Success Criteria (ğŸš¦):** All defined UAT/E2E scenarios PASS. Results comprehensively logged.

### 2.5. Documentation Generation & Review Loop (Sub-Phase: `FEAT_DOC_[FeatureSlug]_005`) - *Can run in parallel with late testing stages if OpProfile allows.*

#### 2.5.1. Draft Technical & User Documentation (Î¼T_FEAT_[FeatureSlug]_DOC_DRAFT_001)
    *   **Directive from `ğŸŒŒWeaverCore`:** `Feature_ğŸ•¸ï¸N_id` (must have status `TESTING_COMPLETE_ jakoÅ›ci_PASS`), all linked `feature_spec_detail_ğŸ•¸ï¸N`, `architecture_design_ğŸ•¸ï¸N`, `CodeModule_ğŸ•¸ï¸N`s. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ“šdoc_writer`.
    *   **Task Description:** Create/update technical (API docs from `Interface_ğŸ•¸ï¸N`s, module descriptions from `CodeModule_ğŸ•¸ï¸N`s with their `docstring_property`) and user-facing documentation (how-to guides, feature explanations from `feature_spec_detail_ğŸ•¸ï¸N.user_stories`) for `Feature_ğŸ•¸ï¸N_id`. LLM, style, detail from `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.documentation_policy`. Query `ğŸ§ cognitive_navigator` (per `DataStrategy`) for `ğŸ•¸ï¸N_doc_template`, `ğŸ•¸ï¸N_style_guide`, and existing relevant `guideâœ¨` pheromones.
    *   **Deliverables:** Draft `TechnicalDoc_ğŸ•¸ï¸N` and `UserDoc_ğŸ•¸ï¸N` linked to `Feature_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas. Files (e.g., Markdown) in `docs/feature_slug/`. Temporary work stored in ğŸ”¥MemoryBank.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `Î¼T_FEAT_[FeatureSlug]_DOC_REVIEW_002`.
    *   **Success Criteria (ğŸš¦):** Draft documents created, stored. Cover all aspects defined in `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.documentation_completeness_checklist`.

#### 2.5.2. Automated & AI-Assisted Documentation Review (Î¼T_FEAT_[FeatureSlug]_DOC_REVIEW_002)
    *   **Directive from `ğŸŒŒWeaverCore`:** Draft `TechnicalDoc_ğŸ•¸ï¸N_id` and `UserDoc_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ§©meta_strategist` (using `mcpğŸ“SequentialThinking` or a "doc-linting-bot" sub-mode, as per `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.documentation_review_tool_policy`).
    *   **Task Description:** Review draft documentation for clarity, accuracy (against specs/arch in ğŸ•¸ï¸Canvas), completeness, grammar, and adherence to `ğŸ•¸ï¸N_style_guide` from Canvas. Check for consistency with actual implemented code behavior (e.g., API endpoint details).
    *   **Deliverables:** `DocReviewReport_ğŸ•¸ï¸N` for each doc type, listing issues or giving approval. Stored in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update (by `ğŸ¤”reflection_engine/scribe`):** IF issues, `warnâ—` on draft doc ğŸ•¸ï¸Ns & `trailğŸ“ˆ` back to `ğŸ“šdoc_writer` for revision `Î¼T_FEAT_..._DOC_REVISE_X`. IF approved, `Documentation_ğŸ•¸ï¸N.status = 'APPROVED'`, and `Feature_ğŸ•¸ï¸N.status_pheromone` becomes `DOCUMENTATION_COMPLETE`. Strong `trailğŸ“ˆ` indicates readiness for Release Review.
    *   **Success Criteria (ğŸš¦):** Documentation reviewed. Status updated to 'APPROVED'. All critical issues resolved.

*(End of Section 2 for one Feature. `ğŸŒŒWeaverCore` proceeds to the next Feature defined in plan.md, or if all features are `DOCUMENTATION_COMPLETE` and/or `READY_FOR_RELEASE_REVIEW`, it may be directed by `ğŸ§©meta_strategist` to start Section 3: Release Preparation.)*

---

## ğŸš€ Section 3: Release Preparation & Deployment - [RELEASE_VERSION_X.Y.Z] (Phase: `REL_PREP_DEPLOY_XYZ`)

**Pheromone Focus (trailğŸ“ˆ for this Phase):** `release_candidate_XYZ_deployment_pipeline`
**Active Configuration (CurrentPhaseConfig_ğŸ•¸ï¸N_id):** `[A NEW CFG_ID_FOR_RELEASE_PHASE, e.g., CFG_RELEASE_XYZ_001, snapshotting OpProfile & TechProfile specific for release activities, set by meta_strategist]`
**Objective:** Package all `Feature_ğŸ•¸ï¸N`s marked with `status_pheromone = DOCUMENTATION_COMPLETE` or `READY_FOR_RELEASE_REVIEW`, perform final release validation, and deploy `[RELEASE_VERSION_X.Y.Z]` to target environment(s) according to `CurrentPhaseConfig_ğŸ•¸ï¸N.OpProfile.deployment_strategy`.

### 3.1. Release Candidate Branching, Versioning & Changelog Generation (Î¼T_REL_BRANCH_VERSION_001)
    *   **Directive from `ğŸŒŒWeaverCore`:** List of `Feature_ğŸ•¸ï¸N_ids` for this release, proposed semantic version `X.Y.Z`, `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸŒŒWeaverCore` (using `execute_command` for Git; `âš¡coder` or `ğŸ“šdoc_writer` for version file & changelog updates).
    *   **Task Description:**
        1.  Create `release/X.Y.Z` branch from `develop` (or `main`, per `TechProfile.branching_model`).
        2.  Merge all feature branches for included `Feature_ğŸ•¸ï¸N`s into `release/X.Y.Z`. Handle merge conflicts (may trigger `ğŸ”debugger` sub-Î¼Ts if complex).
        3.  Tag `vX.Y.Z-rc1` (Release Candidate 1).
        4.  Task `âš¡coder`: Update version numbers in all project files specified in `TechProfile.versioned_files_list` (e.g., `setup.py`, `package.json`, `pom.xml`).
        5.  Task `ğŸ“šdoc_writer` (using `ğŸ§ cognitive_navigator` to pull `Feature_ğŸ•¸ï¸N.summaries` for this release): Generate `CHANGELOG.md` draft for `vX.Y.Z`.
    *   **Deliverables:** `release/X.Y.Z` branch created & stable. `vX.Y.Z-rc1` tag. Version numbers consistent. Draft `CHANGELOG.md`. `ReleaseCandidate_ğŸ•¸ï¸N` created in ğŸ•¸ï¸Canvas, linked to all included `Feature_ğŸ•¸ï¸N`s.
    *   **Pheromone Update:** Strong `trailğŸ“ˆ` on `Î¼T_REL_BUILD_ARTIFACT_002`.
    *   **Success Criteria (ğŸš¦):** Branch & tag exist. CI build (if configured via TechProfile) on release branch PASSES. Version files & changelog updated.

### 3.2. Build & Verify Release Artifacts (Î¼T_REL_BUILD_ARTIFACT_002)
    *   **Directive from `ğŸŒŒWeaverCore`:** `ReleaseCandidate_ğŸ•¸ï¸N_id` (branch `release/X.Y.Z`), `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ³docker_engineer` (if Dockerized, using `TechProfile.docker_build_command_release`) or `â˜ï¸cloud_architect` (for other build systems using `TechProfile.release_build_script_path`).
    *   **Task Description:** Build all specified release artifacts (Docker images, JARs, executables) from the release branch. Perform basic artifact verification (e.g., image scans for critical CVEs using tool in TechProfile, checksum validation). Push artifacts to repository specified in `TechProfile.artifact_repository_url`.
    *   **Deliverables:** Verified `Artifact_ğŸ•¸ï¸N` (type, version, repo_url, checksum, security_scan_status_ğŸš¦) in ğŸ•¸ï¸Canvas, linked to `ReleaseCandidate_ğŸ•¸ï¸N`. Artifacts published.
    *   **Pheromone Update:** `trailğŸ“ˆ` on `Î¼T_REL_STAGING_DEPLOY_003`. If artifact verification fails, `warnâ—` on `ReleaseCandidate_ğŸ•¸ï¸N`.
    *   **Success Criteria (ğŸš¦):** Build successful. Artifacts verified (checksums match, critical CVE scan PASS) and published.

### 3.3. Deploy Release Candidate to Staging Environment (Î¼T_REL_STAGING_DEPLOY_003)
    *   **Directive from `ğŸŒŒWeaverCore`:** `Artifact_ğŸ•¸ï¸N_id` to deploy, `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (which specifies staging environment details from `TechProfile.staging_env_config_ğŸ•¸ï¸N_ref`).
    *   **Assignee:** `â˜ï¸cloud_architect`.
    *   **Task Description:** Deploy the release candidate artifact to the STAGING environment using deployment scripts/IaC defined in `TechProfile.staging_deployment_script_path`.
    *   **Deliverables:** Staging deployment completed. `DeploymentLog_ğŸ•¸ï¸N` (env='staging', status, artifact_deployed) in ğŸ•¸ï¸Canvas.
    *   **Pheromone Update:** `trailğŸ“ˆ` to `Î¼T_REL_STAGING_TEST_004`. `warnâ—` if deployment fails.
    *   **Success Criteria (ğŸš¦):** Deployment to staging successful. Application health checks in staging pass.

### 3.4. Execute Full Regression, Performance & Smoke Tests on Staging (Î¼T_REL_STAGING_TEST_004)
    *   **Directive from `ğŸŒŒWeaverCore`:** Staging environment URL/access. All relevant `TestSuite_ğŸ•¸ï¸N` (Unit, Integration, E2E/UAT) IDs from Canvas features in this release. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (specifies `OpProfile.staging_test_rigor_level`, performance test script paths if any).
    *   **Assignee:** `ğŸ§ªcomprehensive_tester_suite_runner` (conceptual: orchestrates various tester modes or runs a master test script).
    *   **Task Description:** Execute a full battery of automated tests (unit, integration, E2E/UAT, plus any performance/load tests specified by OpProfile for staging) against the staging deployment. Test execution strategy from `CurrentPhaseConfig_ğŸ•¸ï¸N` (e.g., direct or via `ğŸ³docker_engineer`).
    *   **Deliverables:** `MasterStagingTestReport_ğŸ•¸ï¸N` in ğŸ•¸ï¸Canvas, aggregating results from all test suites. Links to individual `TestRun_ğŸ•¸ï¸N`s.
    *   **Pheromone Update:** IF FAIL, strong `warnâ—` on `ReleaseCandidate_ğŸ•¸ï¸N`, detailed `warnâ—` on specific failed test/feature. `trailğŸ“ˆ` to `ğŸ”debugger` (for hotfix on `release/X.Y.Z` branch). IF PASS, `status_pheromone` on `ReleaseCandidate_ğŸ•¸ï¸N` becomes `STAGING_VALIDATED_READY_FOR_PROD_APPROVAL`.
    *   **Success Criteria (ğŸš¦):** ALL designated tests (unit, integration, E2E/UAT, basic performance) PASS on staging. Comprehensive report logged.

### 3.5. Production Deployment Approval Gate (Î¼T_REL_PROD_APPROVAL_005)
    *   **Directive from `ğŸŒŒWeaverCore`:** `ReleaseCandidate_ğŸ•¸ï¸N_id` (must have status `STAGING_VALIDATED_READY_FOR_PROD_APPROVAL`), `MasterStagingTestReport_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `OpProfile.prod_deployment_approval_policy`: 'auto_if_staging_clear_low_dice_r', 'manual_human_ping', 'auto_with_meta_strategist_final_check'). Associated overall release `ğŸ²R_score`.
    *   **Assignee:** `ğŸ§©meta_strategist`.
    *   **Task Description:** Review release candidate readiness for production.
        *   If `OpProfile.policy == 'manual_human_ping'`: PING designated human stakeholder (e.g., email, Slack message via integration or `execute_command` with a script) with summary and link to `MasterStagingTestReport_ğŸ•¸ï¸N`. Await explicit human approval (recorded back to Canvas, possibly via a simple API endpoint Weaver monitors or manual update).
        *   If `OpProfile.policy == 'auto_with_meta_strategist_final_check'`: `ğŸ§©meta_strategist` uses `mcpğŸ“SequentialThinking` with all test reports, ğŸ²R scores, current ğŸ¦budget status, and business priority `trailğŸ“ˆ` from `Feature_ğŸ•¸ï¸N`s in this release to make a GO/NO-GO.
    *   **Deliverables:** `ProductionDeploymentApproval_ğŸ•¸ï¸N` (status: Approved/Rejected, approver, justification/reasoning) in ğŸ•¸ï¸Canvas, linked to `ReleaseCandidate_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** If Approved, strong `trailğŸ“ˆ` to `Î¼T_REL_PROD_DEPLOY_006`. If Rejected, strong `warnâ—` and `trailğŸ“ˆ` to debugging/rollback_planning/re-scoping.
    *   **Success Criteria (ğŸš¦):** Explicit approval decision (automated by `ğŸ§©meta_strategist` or human via callback) logged in `ProductionDeploymentApproval_ğŸ•¸ï¸N`.

### 3.6. Deploy to Production & Smoke Test (Î¼T_REL_PROD_DEPLOY_006)
    *   **Directive from `ğŸŒŒWeaverCore`:** Approved `ReleaseCandidate_ğŸ•¸ï¸N_id` / `Artifact_ğŸ•¸ï¸N_id`. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `TechProfile.production_env_config_ğŸ•¸ï¸N_ref` and `OpProfile.production_deployment_strategy`: e.g., 'blue_green', 'canary_10_percent', 'rolling_update').
    *   **Assignee:** `â˜ï¸cloud_architect`.
    *   **Task Description:** Deploy the approved artifact to the PRODUCTION environment using the strategy specified in OpProfile. This may involve multiple sub-Î¼Tasks for canary phases, traffic shifting, etc. After each stage/full deployment, execute critical smoke tests (`TechProfile.production_smoke_test_script_path`).
    *   **Deliverables:** Production deployment successful. `ProdDeploymentLog_ğŸ•¸ï¸N` (env='production', status, artifact_deployed, strategy_used, smoke_test_status) in ğŸ•¸ï¸Canvas. A new `VersionedRelease_ğŸ•¸ï¸N` for `vX.Y.Z` is created and marked `LIVE`.
    *   **Pheromone Update:** `status_pheromone` on `VersionedRelease_ğŸ•¸ï¸N` (for vX.Y.Z) becomes `LIVE_IN_PRODUCTION`. Strong `trailğŸ“ˆ` for `Î¼T_REL_POST_MONITOR_007`. Announce success on a conceptual `project_status_dashboard_ğŸ•¸ï¸N`.
    *   **Success Criteria (ğŸš¦):** Deployment successful according to chosen strategy. Critical smoke tests PASS in production. `VersionedRelease_ğŸ•¸ï¸N` is LIVE.

### 3.7. Post-Deployment Monitoring & Initial Feedback (Î¼T_REL_POST_MONITOR_007)
    *   **Directive from `ğŸŒŒWeaverCore`:** `VersionedRelease_ğŸ•¸ï¸N_id` that just went LIVE. `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `TechProfile.monitoring_tool_config_details` and `OpProfile.post_release_monitoring_duration_critical` e.g., "1 hour").
    *   **Assignee:** `ğŸ“Šmonitor_setup_agent` (conceptual mode for configuring monitoring tools via APIs/scripts) & `ğŸ¤”reflection_engine` (for actively watching alerts/metrics conceptually fed into Canvas).
    *   **Task Description:**
        1.  `ğŸ“Šmonitor_setup_agent` ensures monitoring dashboards/alerts (e.g., Prometheus, Grafana, Sentry, CloudWatch via APIs/scripts based on `TechProfile.monitoring_tool_setup_instructions_ğŸ•¸ï¸N_ref`) are correctly targeting the new production version and key SLIs/SLOs.
        2.  `ğŸ¤”reflection_engine` actively queries (conceptually) a `LiveMetrics_ğŸ•¸ï¸N` stream from these tools (or summaries pushed to Canvas) for the duration specified in `OpProfile.post_release_monitoring_duration_critical`. Looks for critical error spikes, performance degradations, SLI breaches.
    *   **Deliverables:** Monitoring confirmed active for new release. An initial (`e.g., OpProfile.monitoring_duration`) `PostReleaseHealth_ğŸ•¸ï¸N` summary (key metrics, error rates, any incidents) stored in ğŸ•¸ï¸Canvas linked to `VersionedRelease_ğŸ•¸ï¸N`.
    *   **Pheromone Update:** IF critical anomalies, strong `warnâ—` on `VersionedRelease_ğŸ•¸ï¸N`. This could trigger `ğŸ§©meta_strategist` to consider rollback strategy via `â˜ï¸cloud_architect`. If stable, strengthen `guideâœ¨` on `VersionedRelease_ğŸ•¸ï¸N` indicating stability. Reset `priority_pheromone_strength_trailğŸ“ˆ` on `Project_ğŸ•¸ï¸N` for "next development cycle" or "maintenance mode".
    *   **Success Criteria (ğŸš¦):** Monitoring is verified active and configured. Initial health summary logged. No CRITICAL post-deployment failures exceeding OpProfile thresholds during the defined critical monitoring window.

---

## ğŸ”§ Section 4: System Operations & Autonomous Maintenance (Phase: `SYS_OPS_MAINTAIN_ONGOING`)

**Pheromone Focus (trailğŸ“ˆ types):** `system_maintenance_cycle`, `proactive_security_audit_trigger`, `refactor_opportunity_detected_trailğŸ“ˆ`, `canvas_health_scheduled_check_trailğŸ“ˆ`, `umi_evolution_analysis_trigger`
**Active Configuration:** These tasks use the `CurrentPhaseConfig_ğŸ•¸ï¸N` associated with a general 'MAINTENANCE_OPERATIONS' OpProfile, which is regularly reviewed/updated by `ğŸ§©meta_strategist` via Î¼T_MAINT_BUDGET_REVIEW_CYCLE.
*(These are ongoing, cyclically triggered based on frequencies in the active 'MAINTENANCE_OPERATIONS' OpProfile, or event-driven based on `ğŸ¤”reflection_engine` findings.)*

### 4.1. Scheduled Tech Horizon Scanning Cycle (Î¼T_MAINT_TECHSCAN_CYCLE_[YYYYMMDD])
    *   **Trigger:** `ğŸ§©meta_strategist` based on `Maintenance_OpProfile.tech_scan_frequency`.
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for `perplexity_ask` budget for `ğŸ“¡TechScan`, active TechProfile for list of libs to scan).
    *   **Assignee:** `ğŸ¤”reflection_engine`.
    *   **Task:** Execute `ğŸ“¡TechScan Protocol` as per UMI.
    *   **Deliverables:** `HorizonEvent_ğŸ•¸ï¸N`s in ğŸ•¸ï¸Canvas. `AdaptationProposal_ğŸ•¸ï¸N` for `ğŸ§©meta_strategist`.
    *   **Success Criteria (ğŸš¦):** Scan cycle completed. Findings logged.

### 4.2. Scheduled Cognitive Canvas Integrity Audit Cycle (Î¼T_MAINT_CANVAS_AUDIT_CYCLE_[YYYYMMDD])
    *   **Trigger:** `ğŸ§©meta_strategist` based on `Maintenance_OpProfile.canvas_audit_frequency`.
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ¤”reflection_engine` (or `ğŸ›¡ï¸canvas_auditor` sub-role).
    *   **Task:** Execute `ğŸ›¡ï¸CanvasIntegritySuite`. Maintain `critical_decision_shadow_log.sqlite`. Alert `ğŸ§©meta_strategist` via `â—ğŸ§ Cognitive System Alert` node if issues, potentially triggering switch to `DEGRADED_CANVAS_OPMODE`.
    *   **Deliverables:** `CanvasAuditReport_ğŸ•¸ï¸N`. Shadow log updated.
    *   **Success Criteria (ğŸš¦):** Audit completed. Issues logged/addressed.

### 4.3. Scheduled UMI/Mode/Strategy Effectiveness Review & AMO Proposal Cycle (Î¼T_MAINT_AMO_REVIEW_CYCLE_[YYYYMMDD])
    *   **Trigger:** `ğŸ§©meta_strategist` based on `Maintenance_OpProfile.amo_cycle_frequency`.
    *   **Directive from `ğŸŒŒWeaverCore` includes:** `CurrentPhaseConfig_ğŸ•¸ï¸N_id` (for analysis depth).
    *   **Assignee:** `ğŸ¤”reflection_engine` -> outputs to `ğŸ§©meta_strategist`.
    *   **Task:** Deep analysis of ğŸ•¸ï¸Canvas: UMI section effectiveness, Mode performance, Tooling/Data Strategy outcomes (which ones yield best cost/success/ğŸ²R balance?). Generate `ğŸ•¸ï¸N_improvement_hypothesis` for UMI, Mode definitions, or heuristic rules within OpProfiles (e.g., "Hypothesis: If TechProfile is 'NodeJS_XYZ', always use `london-tester` first for unit tests").
    *   **Deliverables:** `AMO_Report_ğŸ•¸ï¸N`. New/updated `ğŸ•¸ï¸N_improvement_hypothesis` sent to `ğŸ§©meta_strategist` A/B test queue.
    *   **Success Criteria (ğŸš¦):** Cycle completed. Actionable hypotheses logged.

### 4.4. Proactive Refactoring Identification & Planning Cycle (Î¼T_MAINT_REFACTOR_ID_CYCLE_[YYYYMMDD])
    *   **Trigger:** `ğŸ§©meta_strategist` based on `Maintenance_OpProfile.refactor_scan_frequency`.
    *   **Assignee:** `ğŸ¤”reflection_engine` (identification) -> `ğŸ—ï¸architect` (planning if candidate approved by `ğŸ§©meta_strategist`).
    *   **Task:**
        1.  `ğŸ¤”reflection_engine`: Scan ğŸ•¸ï¸Canvas for technical debt: high complexity `CodeModule_ğŸ•¸ï¸N`s, frequently failing test `ğŸ•¸ï¸P_test_failure_cluster`s, components with many recent `warnâ—` pheromones, duplicated `ğŸ•¸ï¸P_code_logic_patterns`.
        2.  Output `RefactoringCandidateReport_ğŸ•¸ï¸N` to `ğŸ§©meta_strategist` with ğŸ²R_technical_debt scores.
        3.  If `ğŸ§©meta_strategist` approves a candidate based on `OpProfile.refactor_approval_threshold_ğŸ²R_debt` and available ğŸ¦budget, it tasks `ğŸ—ï¸architect` to create `RefactoringPlan_ğŸ•¸ï¸N`.
    *   **Deliverables:** `RefactoringCandidateReport_ğŸ•¸ï¸N`. If approved for planning, `RefactoringPlan_ğŸ•¸ï¸N` which details scope, goals, risks, pre/post tests. (Refactoring execution becomes a new feature-like track in Section 2).
    *   **Success Criteria (ğŸš¦):** Scan cycle done. Candidates logged. High-priority refactoring plans exist for approved candidates.

### 4.5. Budget Review & Operational Profile Tuning Cycle (Î¼T_MAINT_BUDGET_REVIEW_CYCLE_[YYYYMMDD])
    *   **Trigger:** `ğŸ§©meta_strategist` based on `Maintenance_OpProfile.budget_review_frequency` or if `ğŸ¦project_budget_ğŸ•¸ï¸N.burn_rate_ğŸ²R_current_vs_target` exceeds OpProfile alert threshold.
    *   **Directive from `ğŸŒŒWeaverCore` (relaying from `ğŸ§©meta_strategist`):** `CurrentPhaseConfig_ğŸ•¸ï¸N_id`.
    *   **Assignee:** `ğŸ§©meta_strategist` (may task `ğŸ’°cost_optimizer` for detailed data crunching and `ğŸ¤”reflection-engine` for cost-saving idea generation).
    *   **Task:** Review current `ğŸ¦project_budget_ğŸ•¸ï¸N` burn rate vs. `Project_ğŸ•¸ï¸N.milestone_dates`. Tune the general 'MAINTENANCE_OPERATIONS' OpProfile OR create/switch to a more specific project OpProfile (e.g., from BALANCED to ULTRA_COST_SAVE_HIBERNATE). Update LLM choices, tool cost thresholds, research budgets, testing rigor parameters within the chosen/tuned OpProfile stored in ğŸ•¸ï¸Canvas.
    *   **Deliverables:** `BudgetReviewReport_ğŸ•¸ï¸N`. Updated parameters in relevant `ğŸ•¸ï¸N_op_profile`(s) in ğŸ•¸ï¸Canvas. Communication to `ğŸŒŒWeaverCore` of any immediate change in active OpProfile.
    *   **Success Criteria (ğŸš¦):** Review cycle completed. Active OpProfile parameters in ğŸ•¸ï¸Canvas are tuned and aligned with current budget reality and project velocity goals.

---

## ğŸ“– Appendix A: Definitions & Conventions

*   **[PROJECT_NAME], [FeatureSlug], etc.:** Placeholders.
*   **ğŸ•¸ï¸N, ğŸ•¸ï¸R, ğŸ•¸ï¸P:** Nodes, Relationships, Paths in Neo4j Cognitive Canvas.
*   **trailğŸ“ˆ, guideâœ¨, warnâ—:** Pheromone types/properties.
*   **ğŸ²R:** Risk Score/Profile (can be a simple score or a complex ğŸ•¸ï¸N).
*   **ğŸš¦:** Success Criteria / Quality Gate status.
*   **ğŸ”¥:** MemoryBank MCP context.
*   **ğŸ§±:** SQLite_KB context.
*   **ğŸ¦:** Budget / Cost / Financial context.
*   **ğŸ’¡:** Generative Innovation Protocol context.
*   **ğŸ“¡:** Tech Horizon Scanning context.
*   **ğŸ›¡ï¸:** Cognitive Canvas Integrity context.
*   **ğŸš©:** Ambiguity Flag/Resolution context.
*   **docsğŸ’°:** Cost Justification context (links to a `Justification_ğŸ•¸ï¸N`).
*   **Î¼T_Phase_Category_ShortName_Seq[.SubSeq]:** Micro-task naming convention.
*   **CurrentPhaseConfig_ğŸ•¸ï¸N_id:** ID of the immutable Neo4j node snapshotting ALL active OpProfile & TechProfile parameters for the current phase. `ğŸŒŒWeaverCore` ensures all modes receive and adhere to this for their Î¼Tasks.
*   **Î¼T_resolved_tooling_and_data_strategy_ğŸ•¸ï¸N_ref:** Pointer to where `ğŸŒŒWeaverCore`'s specific directives for a Î¼T (tool choice, data tier, budget for that step) are logged in the ğŸ•¸ï¸Canvas (likely as properties on the `Î¼T_ğŸ•¸ï¸N` itself or a small linked configuration object).

---
